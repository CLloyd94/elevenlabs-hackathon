2025-02-22 18:26:47,645 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 18:26:47,646 - __main__ - INFO - ElevenLabs API key found
2025-02-22 18:26:47,673 - __main__ - INFO - OpenAI API key found
2025-02-22 18:26:47,674 - __main__ - INFO - Starting Flask application
2025-02-22 18:26:47,674 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 18:26:47,674 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 18:26:47,674 - __main__ - INFO - OpenAI API key present: True
2025-02-22 18:26:47,674 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 18:26:47,685 - werkzeug - WARNING -  * Debugger is active!
2025-02-22 18:26:47,690 - werkzeug - INFO -  * Debugger PIN: 524-160-254
2025-02-22 18:27:11,978 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 18:27:11,979 - __main__ - INFO - ElevenLabs API key found
2025-02-22 18:27:12,006 - __main__ - INFO - OpenAI API key found
2025-02-22 18:27:12,007 - __main__ - INFO - Starting Flask application
2025-02-22 18:27:12,007 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 18:27:12,007 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 18:27:12,007 - __main__ - INFO - OpenAI API key present: True
2025-02-22 18:27:12,007 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 18:27:12,028 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5001
2025-02-22 18:27:12,028 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-02-22 18:27:12,029 - werkzeug - INFO -  * Restarting with stat
2025-02-22 18:27:12,421 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 18:27:12,421 - __main__ - INFO - ElevenLabs API key found
2025-02-22 18:27:12,448 - __main__ - INFO - OpenAI API key found
2025-02-22 18:27:12,449 - __main__ - INFO - Starting Flask application
2025-02-22 18:27:12,449 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 18:27:12,449 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 18:27:12,449 - __main__ - INFO - OpenAI API key present: True
2025-02-22 18:27:12,449 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 18:27:12,459 - werkzeug - WARNING -  * Debugger is active!
2025-02-22 18:27:12,464 - werkzeug - INFO -  * Debugger PIN: 524-160-254
2025-02-22 18:27:23,914 - __main__ - INFO - Serving index page
2025-02-22 18:27:23,929 - werkzeug - INFO - 127.0.0.1 - - [22/Feb/2025 18:27:23] "GET / HTTP/1.1" 200 -
2025-02-22 18:27:26,489 - __main__ - INFO - Serving index page
2025-02-22 18:27:26,492 - werkzeug - INFO - 127.0.0.1 - - [22/Feb/2025 18:27:26] "GET / HTTP/1.1" 200 -
2025-02-22 18:28:43,185 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 18:28:43,186 - __main__ - INFO - ElevenLabs API key found
2025-02-22 18:28:43,213 - __main__ - INFO - OpenAI API key found
2025-02-22 18:28:43,214 - __main__ - INFO - Starting Flask application
2025-02-22 18:28:43,214 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 18:28:43,214 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 18:28:43,214 - __main__ - INFO - OpenAI API key present: True
2025-02-22 18:28:43,214 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 18:28:43,231 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5001
2025-02-22 18:28:43,231 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-02-22 18:28:43,231 - werkzeug - INFO -  * Restarting with stat
2025-02-22 18:28:43,637 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 18:28:43,638 - __main__ - INFO - ElevenLabs API key found
2025-02-22 18:28:43,664 - __main__ - INFO - OpenAI API key found
2025-02-22 18:28:43,665 - __main__ - INFO - Starting Flask application
2025-02-22 18:28:43,665 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 18:28:43,665 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 18:28:43,665 - __main__ - INFO - OpenAI API key present: True
2025-02-22 18:28:43,665 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 18:28:43,676 - werkzeug - WARNING -  * Debugger is active!
2025-02-22 18:28:43,681 - werkzeug - INFO -  * Debugger PIN: 524-160-254
2025-02-22 18:30:45,581 - werkzeug - INFO -  * Detected change in '/Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/voiceover_test.py', reloading
2025-02-22 18:30:45,768 - werkzeug - INFO -  * Restarting with stat
2025-02-22 18:30:46,210 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 18:30:46,211 - __main__ - INFO - ElevenLabs API key found
2025-02-22 18:30:46,238 - __main__ - INFO - OpenAI API key found
2025-02-22 18:30:46,239 - __main__ - INFO - Starting Flask application
2025-02-22 18:30:46,239 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 18:30:46,239 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 18:30:46,239 - __main__ - INFO - OpenAI API key present: True
2025-02-22 18:30:46,239 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 18:30:46,251 - werkzeug - WARNING -  * Debugger is active!
2025-02-22 18:30:46,256 - werkzeug - INFO -  * Debugger PIN: 524-160-254
2025-02-22 18:30:48,274 - werkzeug - INFO -  * Detected change in '/Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/voiceover_test.py', reloading
2025-02-22 18:30:48,383 - werkzeug - INFO -  * Restarting with stat
2025-02-22 18:32:15,192 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 18:32:15,193 - __main__ - INFO - ElevenLabs API key found
2025-02-22 18:32:15,218 - __main__ - INFO - OpenAI API key found
2025-02-22 18:32:15,219 - __main__ - INFO - Starting Quart application
2025-02-22 18:32:15,219 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 18:32:15,219 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 18:32:15,219 - __main__ - INFO - OpenAI API key present: True
2025-02-22 18:32:15,219 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 18:32:15,219 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 18:32:15,239 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 18:32:15,239 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 18:32:21,098 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 60564): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 60564)>
2025-02-22 18:32:21,101 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 60565): <socket.socket fd=9, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 60565)>
2025-02-22 18:32:21,110 - __main__ - INFO - Serving index page
2025-02-22 18:32:53,065 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 18:33:10,392 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 18:33:10,393 - __main__ - INFO - ElevenLabs API key found
2025-02-22 18:33:10,417 - __main__ - INFO - OpenAI API key found
2025-02-22 18:33:10,418 - __main__ - INFO - Starting Quart application
2025-02-22 18:33:10,418 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 18:33:10,418 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 18:33:10,418 - __main__ - INFO - OpenAI API key present: True
2025-02-22 18:33:10,418 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 18:33:10,418 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 18:33:10,436 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 18:33:10,436 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 18:33:15,199 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 60582): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 60582)>
2025-02-22 18:33:15,200 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 60583): <socket.socket fd=9, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 60583)>
2025-02-22 18:33:15,210 - __main__ - INFO - Serving index page
2025-02-22 18:34:56,640 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 18:34:57,270 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 18:34:57,271 - __main__ - INFO - ElevenLabs API key found
2025-02-22 18:34:57,301 - __main__ - INFO - OpenAI API key found
2025-02-22 18:34:57,302 - __main__ - INFO - Starting Quart application
2025-02-22 18:34:57,302 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 18:34:57,302 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 18:34:57,302 - __main__ - INFO - OpenAI API key present: True
2025-02-22 18:34:57,302 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 18:34:57,302 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 18:34:57,321 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 18:34:57,321 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 18:35:13,619 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 18:35:15,625 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 18:35:15,626 - __main__ - INFO - ElevenLabs API key found
2025-02-22 18:35:15,651 - __main__ - INFO - OpenAI API key found
2025-02-22 18:35:15,667 - __main__ - INFO - Starting Quart application
2025-02-22 18:35:15,667 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 18:35:15,667 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 18:35:15,667 - __main__ - INFO - OpenAI API key present: True
2025-02-22 18:35:15,667 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 18:35:15,667 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 18:35:15,685 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 18:35:15,685 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 18:35:23,560 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 60642): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 60642)>
2025-02-22 18:35:23,561 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 60643): <socket.socket fd=9, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 60643)>
2025-02-22 18:35:23,571 - __main__ - INFO - Serving index page
2025-02-22 19:15:46,320 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 19:19:40,574 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:19:40,576 - __main__ - INFO - ElevenLabs API key found
2025-02-22 19:19:40,610 - __main__ - INFO - OpenAI API key found
2025-02-22 19:19:40,626 - __main__ - INFO - Starting Quart application
2025-02-22 19:19:40,626 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 19:19:40,626 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:19:40,626 - __main__ - INFO - OpenAI API key present: True
2025-02-22 19:19:40,626 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 19:19:40,626 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 19:19:40,646 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 19:19:40,646 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 19:19:45,287 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 61124): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 61124)>
2025-02-22 19:19:45,289 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 61125): <socket.socket fd=9, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 61125)>
2025-02-22 19:19:45,302 - __main__ - INFO - Serving index page
2025-02-22 19:20:33,703 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 19:20:34,328 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:20:34,329 - __main__ - INFO - ElevenLabs API key found
2025-02-22 19:20:34,358 - __main__ - INFO - OpenAI API key found
2025-02-22 19:20:34,374 - __main__ - INFO - Starting Quart application
2025-02-22 19:20:34,374 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 19:20:34,374 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:20:34,374 - __main__ - INFO - OpenAI API key present: True
2025-02-22 19:20:34,374 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 19:20:34,374 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 19:20:34,394 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 19:20:34,394 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 19:20:45,044 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 61301): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 61301)>
2025-02-22 19:20:45,046 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 61302): <socket.socket fd=9, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 61302)>
2025-02-22 19:20:45,058 - __main__ - INFO - Serving index page
2025-02-22 19:22:22,563 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 19:22:23,155 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:22:23,156 - __main__ - INFO - ElevenLabs API key found
2025-02-22 19:22:23,186 - __main__ - INFO - OpenAI API key found
2025-02-22 19:22:23,201 - __main__ - INFO - Starting Quart application
2025-02-22 19:22:23,201 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 19:22:23,201 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:22:23,201 - __main__ - INFO - OpenAI API key present: True
2025-02-22 19:22:23,201 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 19:22:23,201 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 19:22:23,221 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 19:22:23,221 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 19:22:28,825 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 61730): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 61730)>
2025-02-22 19:22:28,826 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 61731): <socket.socket fd=9, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 61731)>
2025-02-22 19:22:28,836 - __main__ - INFO - Serving index page
2025-02-22 19:22:48,730 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 19:22:49,236 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:22:49,237 - __main__ - INFO - ElevenLabs API key found
2025-02-22 19:22:49,260 - __main__ - INFO - OpenAI API key found
2025-02-22 19:22:49,276 - __main__ - INFO - Starting Quart application
2025-02-22 19:22:49,276 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 19:22:49,276 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:22:49,276 - __main__ - INFO - OpenAI API key present: True
2025-02-22 19:22:49,276 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 19:22:49,276 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 19:22:49,293 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 19:22:49,293 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 19:23:21,968 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 19:23:22,460 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:23:22,461 - __main__ - INFO - ElevenLabs API key found
2025-02-22 19:23:22,485 - __main__ - INFO - OpenAI API key found
2025-02-22 19:23:22,501 - __main__ - INFO - Starting Quart application
2025-02-22 19:23:22,501 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 19:23:22,501 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:23:22,501 - __main__ - INFO - OpenAI API key present: True
2025-02-22 19:23:22,501 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 19:23:22,501 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 19:23:22,519 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 19:23:22,519 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 19:23:28,607 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 19:23:29,099 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:23:29,099 - __main__ - INFO - ElevenLabs API key found
2025-02-22 19:23:29,123 - __main__ - INFO - OpenAI API key found
2025-02-22 19:23:29,139 - __main__ - INFO - Starting Quart application
2025-02-22 19:23:29,139 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 19:23:29,139 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:23:29,139 - __main__ - INFO - OpenAI API key present: True
2025-02-22 19:23:29,139 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 19:23:29,139 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 19:23:29,156 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 19:23:29,157 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 19:23:46,547 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 19:23:49,388 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:23:49,389 - __main__ - INFO - ElevenLabs API key found
2025-02-22 19:23:49,414 - __main__ - INFO - OpenAI API key found
2025-02-22 19:23:49,430 - __main__ - INFO - Starting Quart application
2025-02-22 19:23:49,430 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 19:23:49,430 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:23:49,430 - __main__ - INFO - OpenAI API key present: True
2025-02-22 19:23:49,430 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 19:23:49,430 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 19:23:49,448 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 19:23:49,448 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 19:23:54,906 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 62107): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 62107)>
2025-02-22 19:23:54,907 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 62108): <socket.socket fd=9, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 62108)>
2025-02-22 19:23:54,914 - __main__ - INFO - Serving index page
2025-02-22 19:23:57,287 - __main__ - INFO - Received script generation request
2025-02-22 19:23:57,288 - __main__ - DEBUG - Request data: {'prompt': 'describe a beautiful kitchen renovation', 'duration': '30'}
2025-02-22 19:23:57,288 - __main__ - INFO - Generating scripts for duration: 30s
2025-02-22 19:23:57,288 - __main__ - INFO - Generating scripts for prompt: describe a beautiful kitchen renovation... (duration: 30s)
2025-02-22 19:23:57,296 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a professional script writer specializing in voiceovers and commercials. \n                Create engaging, natural-sounding scripts that match the timing constraints perfectly. \n                Each script should be carefully timed where speaking at a natural pace would match the specified duration.'}, {'role': 'user', 'content': 'Write 3 different 30-second script variations based on this prompt: describe a beautiful kitchen renovation\n\n                Requirements:\n                1. Each script must be timed to be spoken in exactly 30 seconds at a natural pace\n                2. Use natural, conversational language\n                3. Make each variation distinct but equally engaging\n                4. Focus on clarity and impact\n                5. Avoid any audio/visual directions - just the spoken words\n\n                Return ONLY the three script variations, separated by ||| (three pipes).'}], 'model': 'gpt-4'}}
2025-02-22 19:23:57,330 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-22 19:23:57,330 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-22 19:23:57,368 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106e66450>
2025-02-22 19:23:57,368 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1068ba350> server_hostname='api.openai.com' timeout=5.0
2025-02-22 19:23:57,383 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106e66090>
2025-02-22 19:23:57,383 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-22 19:23:57,383 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-22 19:23:57,383 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-22 19:23:57,383 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-22 19:23:57,383 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-22 19:24:11,590 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 22 Feb 2025 19:24:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-u65kabkbadcebd8ytdwynb4q'), (b'openai-processing-ms', b'13285'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'39761'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'358ms'), (b'x-request-id', b'req_2548ffce7455e687bac55f0f0f5279c0'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=W2PE2.HUgbSqEQOZpjKeNjmpELXObbfajB7iChXeJAc-1740252251-1.0.1.1-qiz5wwjmkJuA8tss2G5KHsfIuiwVZoh8ZdBf.LauwF7iZhx9tp2Qe75OSIx2mp5.Xh5curOMyf3ffiaR9RKEmw; path=/; expires=Sat, 22-Feb-25 19:54:11 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=WVJbWxfb0eW2lU6F1nN5K_8V9NBKeuQ1c0CjytziaJg-1740252251540-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91615a83bd2f14d6-LHR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-22 19:24:11,592 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-22 19:24:11,592 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-22 19:24:11,593 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-22 19:24:11,593 - httpcore.http11 - DEBUG - response_closed.started
2025-02-22 19:24:11,593 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-22 19:24:11,593 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sat, 22 Feb 2025 19:24:11 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-u65kabkbadcebd8ytdwynb4q'), ('openai-processing-ms', '13285'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '40000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '39761'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '358ms'), ('x-request-id', 'req_2548ffce7455e687bac55f0f0f5279c0'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=W2PE2.HUgbSqEQOZpjKeNjmpELXObbfajB7iChXeJAc-1740252251-1.0.1.1-qiz5wwjmkJuA8tss2G5KHsfIuiwVZoh8ZdBf.LauwF7iZhx9tp2Qe75OSIx2mp5.Xh5curOMyf3ffiaR9RKEmw; path=/; expires=Sat, 22-Feb-25 19:54:11 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=WVJbWxfb0eW2lU6F1nN5K_8V9NBKeuQ1c0CjytziaJg-1740252251540-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '91615a83bd2f14d6-LHR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-22 19:24:11,593 - openai._base_client - DEBUG - request_id: req_2548ffce7455e687bac55f0f0f5279c0
2025-02-22 19:24:11,599 - __main__ - DEBUG - GPT-4 response: 1. Stepping into this newly renovated kitchen is like stepping into your dreams. Glistening marble countertops that seem to stretch forever, under softly glowing pendant lights. Bespoke built-ins boasting plenty of storage, for pots, pans, and pastry cutters. An island so grand, it’s practically it's own continent, perfect for buffet spreads. Natural sunlight cascades through expansive windows, splashing warmth onto antique herringbone wooden floors. And with state-of-the-art appliances, whipping up your favorite dish becomes an easy masterpiece. Welcome to the heart of your home, reimagined. 

|||

2. Imagine your home's heart beating to the rhythm of a kitchen renovation, flawlessly tailored to your story. White quartz countertops sparkling, rubbing shoulders with high-end, stainless steel appliances. Hand-crafted cabinetry flowing seamlessly, merging form and function. A center island inviting connection, laughter, shared meals. Picture underfloor heating tickling your toes on cold mornings, offering comforting warmth against the backdrop of rustic farmhouse-style wood flooring. Every inch is a testament to both beauty and practicality. It's not just a renovation, it's a lifestyle upgrade. 

|||

3. Welcome to the kitchen renovation of your dreams. Imagine running your fingers over the sleek, granite countertops, chilled against your touch. Ambient pendant lights cast a soft, soulful glow, highlighting the deep grain of custom cabinetry. An opulent island stands ready, poised for family gatherings and culinary adventures. Sink your feet into warmed wooden floors, as skylights pour in heaven-sent brightness, highlighting the blend of elegant designs and leading-edge appliances. A symphony of function and aesthetics, where every detail sings in perfect harmony. Your dream home-checked one kitchen at a time.
2025-02-22 19:24:11,600 - __main__ - INFO - Generated 3 script variations
2025-02-22 19:24:11,600 - __main__ - INFO - Scripts generated successfully
2025-02-22 19:26:52,570 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 19:26:53,059 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:26:53,060 - __main__ - INFO - ElevenLabs API key found
2025-02-22 19:26:53,084 - __main__ - INFO - OpenAI API key found
2025-02-22 19:26:53,100 - __main__ - INFO - Starting Quart application
2025-02-22 19:26:53,100 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 19:26:53,100 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:26:53,100 - __main__ - INFO - OpenAI API key present: True
2025-02-22 19:26:53,100 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 19:26:53,100 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 19:26:53,118 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 19:26:53,118 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 19:28:51,581 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 19:28:52,054 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:28:52,055 - __main__ - INFO - ElevenLabs API key found
2025-02-22 19:28:52,080 - __main__ - INFO - OpenAI API key found
2025-02-22 19:28:52,096 - __main__ - INFO - Starting Quart application
2025-02-22 19:28:52,096 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 19:28:52,096 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:28:52,096 - __main__ - INFO - OpenAI API key present: True
2025-02-22 19:28:52,096 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 19:28:52,096 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 19:28:52,114 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 19:28:52,114 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 19:28:57,184 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 19:28:57,678 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:28:57,678 - __main__ - INFO - ElevenLabs API key found
2025-02-22 19:28:57,702 - __main__ - INFO - OpenAI API key found
2025-02-22 19:28:57,718 - __main__ - INFO - Starting Quart application
2025-02-22 19:28:57,718 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 19:28:57,718 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:28:57,718 - __main__ - INFO - OpenAI API key present: True
2025-02-22 19:28:57,718 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 19:28:57,719 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 19:28:57,736 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 19:28:57,736 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 19:29:02,812 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 19:29:03,347 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:29:03,347 - __main__ - INFO - ElevenLabs API key found
2025-02-22 19:29:03,371 - __main__ - INFO - OpenAI API key found
2025-02-22 19:29:03,389 - __main__ - INFO - Starting Quart application
2025-02-22 19:29:03,389 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 19:29:03,389 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:29:03,389 - __main__ - INFO - OpenAI API key present: True
2025-02-22 19:29:03,389 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 19:29:03,389 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 19:29:03,407 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 19:29:03,407 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 19:29:15,235 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 63447): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 63447)>
2025-02-22 19:29:15,245 - __main__ - INFO - Received script generation request
2025-02-22 19:29:15,248 - __main__ - DEBUG - Request data: {'prompt': 'describe a beautiful kitchen renovation', 'duration': '30'}
2025-02-22 19:29:15,248 - __main__ - INFO - Generating scripts for duration: 30s
2025-02-22 19:29:15,248 - __main__ - INFO - Generating scripts for prompt: describe a beautiful kitchen renovation... (duration: 30s)
2025-02-22 19:29:15,253 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a professional script writer specializing in voiceovers and commercials. \n                Create engaging, natural-sounding scripts that match the timing constraints perfectly. \n                Each script should be carefully timed where speaking at a natural pace would match the specified duration.'}, {'role': 'user', 'content': 'Write 3 different 30-second script variations based on this prompt: describe a beautiful kitchen renovation\n\n                Requirements:\n                1. Each script must be timed to be spoken in exactly 30 seconds at a natural pace\n                2. Use natural, conversational language\n                3. Make each variation distinct but equally engaging\n                4. Focus on clarity and impact\n                5. Avoid any audio/visual directions - just the spoken words\n                6. Keep the length to no more than 3 sentences.\n\n                Return ONLY the three script variations, separated by ||| (three pipes).'}], 'model': 'gpt-4'}}
2025-02-22 19:29:15,276 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-22 19:29:15,276 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-22 19:29:15,308 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10bdf8410>
2025-02-22 19:29:15,308 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10c1c6350> server_hostname='api.openai.com' timeout=5.0
2025-02-22 19:29:15,321 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10c659d30>
2025-02-22 19:29:15,321 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-22 19:29:15,322 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-22 19:29:15,322 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-22 19:29:15,322 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-22 19:29:15,322 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-22 19:29:24,729 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 22 Feb 2025 19:29:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-u65kabkbadcebd8ytdwynb4q'), (b'openai-processing-ms', b'9103'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'39745'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'382ms'), (b'x-request-id', b'req_7194e845bfb593147fb30e257ca75ec9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Dj5JXOFyGsJ8jVs_ODEDuCTWjDSzQoWmOwYVWMCZTzM-1740252564-1.0.1.1-pG_36Cd5e1j.cCZJsg75LX9bcSnikvZGxW5yoAJcNan4PU.nzqwfwVvRwiXu_VLMLPHmc06ANDklMnE9DwWMKg; path=/; expires=Sat, 22-Feb-25 19:59:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=cNUcf7n4Y6yUd2h3X8OxffF7euCqS46uAGD5COmqiXg-1740252564636-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91616246ea204141-LHR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-22 19:29:24,732 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-22 19:29:24,732 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-22 19:29:24,732 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-22 19:29:24,733 - httpcore.http11 - DEBUG - response_closed.started
2025-02-22 19:29:24,733 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-22 19:29:24,733 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sat, 22 Feb 2025 19:29:24 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-u65kabkbadcebd8ytdwynb4q'), ('openai-processing-ms', '9103'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '40000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '39745'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '382ms'), ('x-request-id', 'req_7194e845bfb593147fb30e257ca75ec9'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Dj5JXOFyGsJ8jVs_ODEDuCTWjDSzQoWmOwYVWMCZTzM-1740252564-1.0.1.1-pG_36Cd5e1j.cCZJsg75LX9bcSnikvZGxW5yoAJcNan4PU.nzqwfwVvRwiXu_VLMLPHmc06ANDklMnE9DwWMKg; path=/; expires=Sat, 22-Feb-25 19:59:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=cNUcf7n4Y6yUd2h3X8OxffF7euCqS46uAGD5COmqiXg-1740252564636-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '91616246ea204141-LHR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-22 19:29:24,733 - openai._base_client - DEBUG - request_id: req_7194e845bfb593147fb30e257ca75ec9
2025-02-22 19:29:24,739 - __main__ - DEBUG - GPT-4 response: 1. "Imagine stepping into your dream kitchen every morning. Shiny stainless-steel appliances, sleek granite countertops that glisten under soft pendant lights, and the warm hue of custom wooden cabinetry waiting to greet you. A beautiful kitchen is not just a renovation, it's the heart of your home seeking to delight you every single day."

|||

2. "Have a moment to picture life with your recently revamped kitchen. Marvel at the exquisite, timeless marble countertops meeting with high-end, energy-efficient appliances. Feel the difference as smooth, reclaimed oak flooring leads you around, enriching the charm of your kitchen, your home's culinary art studio."

|||

3. "Visualize pushing open the doors to your freshly renovated kitchen. It's a masterpiece featuring sparkling quartz countertops, smart, cutting-edge appliances that gleam with promise, and beautifully crafted cabinets, telling the tale of your impeccable taste. It's more than just a room, it's the soul of your home, waiting to add a pinch of comfort and a dash of joy to your life."
2025-02-22 19:29:24,740 - __main__ - INFO - Generated 3 script variations
2025-02-22 19:29:24,740 - __main__ - INFO - Scripts generated successfully
2025-02-22 19:29:40,035 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 19:29:40,538 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:29:40,539 - __main__ - INFO - ElevenLabs API key found
2025-02-22 19:29:40,564 - __main__ - INFO - OpenAI API key found
2025-02-22 19:29:40,580 - __main__ - INFO - Starting Quart application
2025-02-22 19:29:40,580 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 19:29:40,580 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:29:40,580 - __main__ - INFO - OpenAI API key present: True
2025-02-22 19:29:40,580 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 19:29:40,580 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 19:29:40,607 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 19:29:40,607 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 19:29:44,660 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 19:29:45,144 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:29:45,145 - __main__ - INFO - ElevenLabs API key found
2025-02-22 19:29:45,170 - __main__ - INFO - OpenAI API key found
2025-02-22 19:29:45,224 - __main__ - INFO - Starting Quart application
2025-02-22 19:29:45,224 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 19:29:45,224 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:29:45,224 - __main__ - INFO - OpenAI API key present: True
2025-02-22 19:29:45,224 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 19:29:45,224 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 19:29:45,241 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 19:29:45,242 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 19:29:49,055 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 63589): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 63589)>
2025-02-22 19:29:49,067 - __main__ - INFO - Received script generation request
2025-02-22 19:29:49,069 - __main__ - DEBUG - Request data: {'prompt': 'describe a beautiful kitchen renovation', 'duration': '30'}
2025-02-22 19:29:49,069 - __main__ - INFO - Generating scripts for duration: 30s
2025-02-22 19:29:49,069 - __main__ - INFO - Generating scripts for prompt: describe a beautiful kitchen renovation... (duration: 30s)
2025-02-22 19:29:49,071 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a professional script writer specializing in voiceovers and commercials. \n                Create engaging, natural-sounding scripts that match the timing constraints perfectly. \n                Each script should be carefully timed where speaking at a natural pace would match the specified duration.'}, {'role': 'user', 'content': 'Write 3 different 30-second script variations based on this prompt: describe a beautiful kitchen renovation\n\n                Requirements:\n                1. Each script must be timed to be spoken in exactly 30 seconds at a natural pace\n                2. Use natural, conversational language\n                3. Make each variation distinct but equally engaging\n                4. Focus on clarity and impact\n                5. Avoid any audio/visual directions - just the spoken words\n                6. Keep the length to no more than 3 sentences.\n                7. Keep sentences short.\n\n                Return ONLY the three script variations, separated by ||| (three pipes).'}], 'model': 'gpt-4'}}
2025-02-22 19:29:49,082 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-22 19:29:49,083 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-22 19:29:49,097 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11015df10>
2025-02-22 19:29:49,097 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1059c6350> server_hostname='api.openai.com' timeout=5.0
2025-02-22 19:29:49,108 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11015de20>
2025-02-22 19:29:49,108 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-22 19:29:49,108 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-22 19:29:49,108 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-22 19:29:49,108 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-22 19:29:49,109 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-22 19:29:56,195 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 22 Feb 2025 19:29:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-u65kabkbadcebd8ytdwynb4q'), (b'openai-processing-ms', b'6875'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'39735'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'397ms'), (b'x-request-id', b'req_28169ea1f644587af24c2e5a5ce6e0e2'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Jki1kqclzgSUVWb.0AnN_AwrnefKwmBCcz05KWkUkUo-1740252596-1.0.1.1-NehI.UlBFQ9y9QFNlO_Dx.u8jl1tTwsQvcZyq0Vu.0OL1LL_5y_TSzZ5ogUdXnz6E2onO9lIL8E5HOT1u_XlMw; path=/; expires=Sat, 22-Feb-25 19:59:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=v2ZhqcGQKDwMpFmjYeqRFyE13y30jTmD5EIwymUP7rI-1740252596204-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9161631a0e3494f6-LHR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-22 19:29:56,197 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-22 19:29:56,198 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-22 19:29:56,201 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-22 19:29:56,201 - httpcore.http11 - DEBUG - response_closed.started
2025-02-22 19:29:56,202 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-22 19:29:56,202 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sat, 22 Feb 2025 19:29:56 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-u65kabkbadcebd8ytdwynb4q'), ('openai-processing-ms', '6875'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '40000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '39735'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '397ms'), ('x-request-id', 'req_28169ea1f644587af24c2e5a5ce6e0e2'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Jki1kqclzgSUVWb.0AnN_AwrnefKwmBCcz05KWkUkUo-1740252596-1.0.1.1-NehI.UlBFQ9y9QFNlO_Dx.u8jl1tTwsQvcZyq0Vu.0OL1LL_5y_TSzZ5ogUdXnz6E2onO9lIL8E5HOT1u_XlMw; path=/; expires=Sat, 22-Feb-25 19:59:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=v2ZhqcGQKDwMpFmjYeqRFyE13y30jTmD5EIwymUP7rI-1740252596204-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9161631a0e3494f6-LHR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-22 19:29:56,203 - openai._base_client - DEBUG - request_id: req_28169ea1f644587af24c2e5a5ce6e0e2
2025-02-22 19:29:56,208 - __main__ - DEBUG - GPT-4 response: 1. "Imagine stepping into a kitchen that takes your breath away! Gleaming marble counters, rich mahogany cabinets, and cutting-edge appliances at your fingertips. A place that feels not just like a kitchen, but the very heart of your home." 
|||
2. "There's nothing like a freshly renovated kitchen. Picture this - Pure white quartz countertops, shiny new stainless-steel appliances and thoughtfully designed cabinetry that provides ample storage. It's the perfect blend of style and functionality that leaves you saying 'Wow!'." 
|||
3. "Imagine a kitchen that captures the joy of cooking in style. It's all about a granite island surrounded by bespoke hardwood cupboards, all bathed in warm, ambient lighting. Your dream of a picture-perfect kitchen truly comes to life."
2025-02-22 19:29:56,208 - __main__ - INFO - Generated 3 script variations
2025-02-22 19:29:56,208 - __main__ - INFO - Scripts generated successfully
2025-02-22 19:30:26,471 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 63734): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 63734)>
2025-02-22 19:30:26,476 - __main__ - INFO - Received voiceover generation request
2025-02-22 19:30:26,478 - __main__ - DEBUG - Request data: {'text': '3. "Imagine a kitchen that captures the joy of cooking in style. It\'s all about a granite island surrounded by bespoke hardwood cupboards, all bathed in warm, ambient lighting. Your dream of a picture-perfect kitchen truly comes to life."', 'voice': 'JBFqnCBsd6RMkjVDRZzb'}
2025-02-22 19:30:26,478 - __main__ - INFO - Generating voiceover for text: 3. "Imagine a kitchen that captures the joy of cooking in style. It's all about a granite island sur...
2025-02-22 19:30:26,479 - __main__ - INFO - Using voice ID: JBFqnCBsd6RMkjVDRZzb
2025-02-22 19:30:26,479 - __main__ - DEBUG - Calling ElevenLabs API
2025-02-22 19:30:26,479 - __main__ - DEBUG - Converting audio generator to bytes
2025-02-22 19:30:26,480 - httpcore.connection - DEBUG - connect_tcp.started host='api.elevenlabs.io' port=443 local_address=None timeout=60 socket_options=None
2025-02-22 19:30:26,500 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11015ef90>
2025-02-22 19:30:26,500 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1059c60d0> server_hostname='api.elevenlabs.io' timeout=60
2025-02-22 19:30:26,516 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11015e9c0>
2025-02-22 19:30:26,516 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-22 19:30:26,517 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-22 19:30:26,517 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-22 19:30:26,517 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-22 19:30:26,517 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-22 19:30:29,642 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Sat, 22 Feb 2025 19:30:26 GMT'), (b'server', b'uvicorn'), (b'request-id', b'Qb4kfdQqJUftxCAOPAVS'), (b'access-control-expose-headers', b'request-id, history-item-id, character-cost, regeneration-count, generation-info, current-concurrent-requests, maximum-concurrent-requests'), (b'history-item-id', b'53avDxYbBivk8mlPJX6Y'), (b'current-concurrent-requests', b'1'), (b'maximum-concurrent-requests', b'2'), (b'character-cost', b'238'), (b'tts-latency-ms', b'2680'), (b'Content-Length', b'233221'), (b'content-type', b'audio/mpeg'), (b'access-control-allow-origin', b'*'), (b'access-control-allow-headers', b'*'), (b'access-control-allow-methods', b'POST, PATCH, OPTIONS, DELETE, GET, PUT'), (b'access-control-max-age', b'600'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), (b'x-trace-id', b'b3cdef4c1ea0771f4ea41501f0149c28'), (b'Via', b'1.1 google'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000')])
2025-02-22 19:30:29,643 - httpx - INFO - HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb?output_format=mp3_44100_128 "HTTP/1.1 200 OK"
2025-02-22 19:30:29,643 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-22 19:30:29,679 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-22 19:30:29,679 - httpcore.http11 - DEBUG - response_closed.started
2025-02-22 19:30:29,679 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-22 19:30:29,679 - __main__ - DEBUG - Generated 233221 bytes of audio data
2025-02-22 19:30:29,680 - __main__ - DEBUG - Saving audio to /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp/voiceover_7162244133276131058.mp3
2025-02-22 19:30:29,681 - __main__ - INFO - Voiceover generated and saved successfully
2025-02-22 19:30:29,684 - asyncio - WARNING - Executing <Task finished name='Task-19' coro=<ASGIHTTPConnection.handle_request() done, defined at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/asgi.py:106> result=None created at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 3.208 seconds
2025-02-22 19:30:29,699 - __main__ - INFO - Serving audio file: voiceover_7162244133276131058.mp3
2025-02-22 19:30:29,720 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 63736): <socket.socket fd=17, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 63736)>
2025-02-22 19:31:01,358 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 19:31:01,858 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:31:01,858 - __main__ - INFO - ElevenLabs API key found
2025-02-22 19:31:01,883 - __main__ - INFO - OpenAI API key found
2025-02-22 19:31:01,899 - __main__ - INFO - Starting Quart application
2025-02-22 19:31:01,899 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 19:31:01,899 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:31:01,899 - __main__ - INFO - OpenAI API key present: True
2025-02-22 19:31:01,899 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 19:31:01,899 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 19:31:01,917 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 19:31:01,917 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 19:31:02,918 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 19:31:03,415 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:31:03,416 - __main__ - INFO - ElevenLabs API key found
2025-02-22 19:31:03,440 - __main__ - INFO - OpenAI API key found
2025-02-22 19:31:03,456 - __main__ - INFO - Starting Quart application
2025-02-22 19:31:03,456 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 19:31:03,456 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:31:03,456 - __main__ - INFO - OpenAI API key present: True
2025-02-22 19:31:03,456 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 19:31:03,456 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 19:31:03,473 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 19:31:03,474 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 19:32:10,935 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 19:32:11,460 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:32:11,461 - __main__ - INFO - ElevenLabs API key found
2025-02-22 19:32:11,485 - __main__ - INFO - OpenAI API key found
2025-02-22 19:32:11,501 - __main__ - INFO - Starting Quart application
2025-02-22 19:32:11,501 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 19:32:11,501 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:32:11,501 - __main__ - INFO - OpenAI API key present: True
2025-02-22 19:32:11,501 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 19:32:11,501 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 19:32:11,518 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 19:32:11,518 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 19:32:13,534 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 19:32:14,015 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:32:14,016 - __main__ - INFO - ElevenLabs API key found
2025-02-22 19:32:14,039 - __main__ - INFO - OpenAI API key found
2025-02-22 19:32:14,055 - __main__ - INFO - Starting Quart application
2025-02-22 19:32:14,056 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 19:32:14,056 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:32:14,056 - __main__ - INFO - OpenAI API key present: True
2025-02-22 19:32:14,056 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 19:32:14,056 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 19:32:14,073 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 19:32:14,073 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 19:32:58,119 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 63764): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 63764)>
2025-02-22 19:32:58,128 - __main__ - INFO - Received script generation request
2025-02-22 19:32:58,131 - __main__ - DEBUG - Request data: {'prompt': 'describe a beautiful kitchen renovation', 'duration': '30'}
2025-02-22 19:32:58,131 - __main__ - INFO - Generating scripts for duration: 30s
2025-02-22 19:32:58,131 - __main__ - INFO - Generating scripts for prompt: describe a beautiful kitchen renovation... (duration: 30s)
2025-02-22 19:32:58,135 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a professional script writer specializing in voiceovers and commercials. \n                Create engaging, natural-sounding scripts that match the timing constraints perfectly. \n                Each script should be carefully timed where speaking at a natural pace would match the specified duration.'}, {'role': 'user', 'content': "Write 3 different 30-second script variations based on this prompt: describe a beautiful kitchen renovation\n\n                Requirements:\n                1. Each script must be timed to be spoken in exactly 30 seconds at a natural pace\n                2. Use natural, conversational language\n                3. Make each variation distinct but equally engaging\n                4. Focus on clarity and impact\n                5. Avoid any audio/visual directions - just the spoken words\n                6. Keep the length to no more than 3 sentences.\n                7. Keep sentences short.\n                8. Finish with a call-to-action like 'get your estimate' or 'learn more'.\n\n                Return ONLY the three script variations, separated by ||| (three pipes)."}], 'model': 'gpt-4'}}
2025-02-22 19:32:58,153 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-22 19:32:58,153 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-22 19:32:58,179 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1078599a0>
2025-02-22 19:32:58,179 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1062c6350> server_hostname='api.openai.com' timeout=5.0
2025-02-22 19:32:58,191 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10625dd90>
2025-02-22 19:32:58,191 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-22 19:32:58,191 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-22 19:32:58,191 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-22 19:32:58,191 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-22 19:32:58,191 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-22 19:33:04,395 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 22 Feb 2025 19:33:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-u65kabkbadcebd8ytdwynb4q'), (b'openai-processing-ms', b'5999'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'39712'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'432ms'), (b'x-request-id', b'req_1ce0003f9415b86aa1aab687df520a70'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=RRt2urtK2sM5c3Ue_74WvsTsN45.zq9gZISPbdCXtdo-1740252784-1.0.1.1-QKCNGeAVqH_5haucAxaR_gYMsPh9.f0FFYa0anfQIqStG_vJ_DFhIaTuiCMM5eydjbFKYWpb_wW8IEbjScyddQ; path=/; expires=Sat, 22-Feb-25 20:03:04 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=fEcKj6LPI06_aU_eecmbXiBSP341uSqUH9AJNZU2NQI-1740252784403-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'916167b7c9da93d9-LHR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-22 19:33:04,399 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-22 19:33:04,399 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-22 19:33:04,399 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-22 19:33:04,399 - httpcore.http11 - DEBUG - response_closed.started
2025-02-22 19:33:04,400 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-22 19:33:04,400 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sat, 22 Feb 2025 19:33:04 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-u65kabkbadcebd8ytdwynb4q'), ('openai-processing-ms', '5999'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '40000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '39712'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '432ms'), ('x-request-id', 'req_1ce0003f9415b86aa1aab687df520a70'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=RRt2urtK2sM5c3Ue_74WvsTsN45.zq9gZISPbdCXtdo-1740252784-1.0.1.1-QKCNGeAVqH_5haucAxaR_gYMsPh9.f0FFYa0anfQIqStG_vJ_DFhIaTuiCMM5eydjbFKYWpb_wW8IEbjScyddQ; path=/; expires=Sat, 22-Feb-25 20:03:04 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=fEcKj6LPI06_aU_eecmbXiBSP341uSqUH9AJNZU2NQI-1740252784403-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '916167b7c9da93d9-LHR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-22 19:33:04,400 - openai._base_client - DEBUG - request_id: req_1ce0003f9415b86aa1aab687df520a70
2025-02-22 19:33:04,408 - __main__ - DEBUG - GPT-4 response: Variation 1:
Imagine your dream kitchen — gleaming countertops, elegantly styled cabinets, and state-of-the-art appliances. Flawlessly marrying functionality with taste. Best part? It's all achievable with our bespoke kitchen renovations — we tailor dreams to suit your budget. Let's plan your kitchen transformation, get your estimate now!

Variation 2:
Cook more than meals; cook up memories in a beautifully renovated kitchen. Think shabby chic meets modern efficiency, where every day feels like a gourmet experience. Ready to spice up your life with a dash of elegance? Speak to our experts today, let them whip up a new recipe for your kitchen's look!

Variation 3:
Turn the heart of your home into an exquisite culinary canvas with our kitchen renovation services. Unleash your inner chef amid granite reclaimed-wood, stainless steel stoves, and smart storage solutions. To master the art of beautiful living, discover our kitchen renovations. Make your dream kitchen a reality—learn more today!
2025-02-22 19:33:04,409 - __main__ - INFO - Generated 1 script variations
2025-02-22 19:33:04,409 - __main__ - INFO - Scripts generated successfully
2025-02-22 19:33:28,561 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 19:33:29,050 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:33:29,050 - __main__ - INFO - ElevenLabs API key found
2025-02-22 19:33:29,074 - __main__ - INFO - OpenAI API key found
2025-02-22 19:33:29,090 - __main__ - INFO - Starting Quart application
2025-02-22 19:33:29,090 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 19:33:29,090 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:33:29,090 - __main__ - INFO - OpenAI API key present: True
2025-02-22 19:33:29,090 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 19:33:29,090 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 19:33:29,108 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 19:33:29,108 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 19:33:32,224 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 63779): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 63779)>
2025-02-22 19:33:32,232 - __main__ - INFO - Received script generation request
2025-02-22 19:33:32,233 - __main__ - DEBUG - Request data: {'prompt': 'describe a beautiful kitchen renovation', 'duration': '30'}
2025-02-22 19:33:32,233 - __main__ - INFO - Generating scripts for duration: 30s
2025-02-22 19:33:32,233 - __main__ - INFO - Generating scripts for prompt: describe a beautiful kitchen renovation... (duration: 30s)
2025-02-22 19:33:32,235 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a professional script writer specializing in voiceovers and commercials. \n                Create engaging, natural-sounding scripts that match the timing constraints perfectly. \n                Each script should be carefully timed where speaking at a natural pace would match the specified duration.'}, {'role': 'user', 'content': "Write 3 different 30-second script variations based on this prompt: describe a beautiful kitchen renovation\n\n                Requirements:\n                1. Each script must be timed to be spoken in exactly 30 seconds at a natural pace\n                2. Use natural, conversational language\n                3. Make each variation distinct but equally engaging\n                4. Focus on clarity and impact\n                5. Avoid any audio/visual directions - just the spoken words\n                6. Keep the length to no more than 3 sentences.\n                7. Keep sentences short.\n                8. The last sentence should be a call-to-action like 'get your estimate' or 'learn more'.\n\n                Return ONLY the three script variations, separated by ||| (three pipes)."}], 'model': 'gpt-4'}}
2025-02-22 19:33:32,249 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-22 19:33:32,249 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-22 19:33:32,258 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106b86720>
2025-02-22 19:33:32,259 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1068fa350> server_hostname='api.openai.com' timeout=5.0
2025-02-22 19:33:32,271 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106b86000>
2025-02-22 19:33:32,271 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-22 19:33:32,271 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-22 19:33:32,271 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-22 19:33:32,271 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-22 19:33:32,271 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-22 19:33:38,732 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 22 Feb 2025 19:33:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-u65kabkbadcebd8ytdwynb4q'), (b'openai-processing-ms', b'6217'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'39708'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'438ms'), (b'x-request-id', b'req_9b6986b68191b42dfdb1e8b9788e98b7'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=3piEqLcdONwMh072_HuTdP8HxFCXjtjBYAoN5RWoqmU-1740252818-1.0.1.1-k785dQQoDZa53am9Js47LgeeH.zX5oOg3H.slZ5tHZjQwlzEO04M5UWSf8R3Wy489AcRpDWjeXoeaNU2cE.GeQ; path=/; expires=Sat, 22-Feb-25 20:03:38 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=V0EXCjoJ.jhBcQ5erhBySQYS5d1aXF_JDd46BB._Bgo-1740252818714-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9161688cdb4d93d9-LHR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-22 19:33:38,736 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-22 19:33:38,736 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-22 19:33:38,737 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-22 19:33:38,737 - httpcore.http11 - DEBUG - response_closed.started
2025-02-22 19:33:38,737 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-22 19:33:38,737 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sat, 22 Feb 2025 19:33:38 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-u65kabkbadcebd8ytdwynb4q'), ('openai-processing-ms', '6217'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '40000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '39708'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '438ms'), ('x-request-id', 'req_9b6986b68191b42dfdb1e8b9788e98b7'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=3piEqLcdONwMh072_HuTdP8HxFCXjtjBYAoN5RWoqmU-1740252818-1.0.1.1-k785dQQoDZa53am9Js47LgeeH.zX5oOg3H.slZ5tHZjQwlzEO04M5UWSf8R3Wy489AcRpDWjeXoeaNU2cE.GeQ; path=/; expires=Sat, 22-Feb-25 20:03:38 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=V0EXCjoJ.jhBcQ5erhBySQYS5d1aXF_JDd46BB._Bgo-1740252818714-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9161688cdb4d93d9-LHR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-22 19:33:38,738 - openai._base_client - DEBUG - request_id: req_9b6986b68191b42dfdb1e8b9788e98b7
2025-02-22 19:33:38,746 - __main__ - DEBUG - GPT-4 response: 1. Picture this. You step into your new kitchen, awash in warm sunlight filtering through elegant French windows. A stunning quartz countertop gleams under pendant lights, capturing the essence of your sophisticated tastes. Don't just imagine—bring your dream kitchen to life today. Get your free estimate now!

|||

2. Welcome home, to a kitchen that strikes the perfect balance of function and design. Stainless steel appliances, hardwood flooring, and custom cabinets, all singing in harmony to your culinary tune. Your beautiful kitchen transformation is but a click away. Let's start this exciting journey together!

|||

3.  Experience a transformation like no other, a kitchen reimagined just for you. Beautiful marble surfaces blend seamlessly with a timeless subway tile backsplash. Join us and make this picture-perfect kitchen your reality. Learn more about our personalized renovation plans now!
2025-02-22 19:33:38,746 - __main__ - INFO - Generated 3 script variations
2025-02-22 19:33:38,746 - __main__ - INFO - Scripts generated successfully
2025-02-22 19:33:47,989 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 63781): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 63781)>
2025-02-22 19:33:47,995 - __main__ - INFO - Received voiceover generation request
2025-02-22 19:33:47,996 - __main__ - DEBUG - Request data: {'text': '3.  Experience a transformation like no other, a kitchen reimagined just for you. Beautiful marble surfaces blend seamlessly with a timeless subway tile backsplash. Join us and make this picture-perfect kitchen your reality. Learn more about our personalized renovation plans now!', 'voice': 'JBFqnCBsd6RMkjVDRZzb'}
2025-02-22 19:33:47,996 - __main__ - INFO - Generating voiceover for text: 3.  Experience a transformation like no other, a kitchen reimagined just for you. Beautiful marble s...
2025-02-22 19:33:47,996 - __main__ - INFO - Using voice ID: JBFqnCBsd6RMkjVDRZzb
2025-02-22 19:33:47,996 - __main__ - DEBUG - Calling ElevenLabs API
2025-02-22 19:33:47,996 - __main__ - DEBUG - Converting audio generator to bytes
2025-02-22 19:33:47,998 - httpcore.connection - DEBUG - connect_tcp.started host='api.elevenlabs.io' port=443 local_address=None timeout=60 socket_options=None
2025-02-22 19:33:48,008 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106b87350>
2025-02-22 19:33:48,008 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1068fa0d0> server_hostname='api.elevenlabs.io' timeout=60
2025-02-22 19:33:48,024 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106b85c10>
2025-02-22 19:33:48,025 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-22 19:33:48,025 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-22 19:33:48,025 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-22 19:33:48,025 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-22 19:33:48,025 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-22 19:33:51,849 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Sat, 22 Feb 2025 19:33:47 GMT'), (b'server', b'uvicorn'), (b'request-id', b'PIpu38HEsiasbmY6kHN1'), (b'access-control-expose-headers', b'request-id, history-item-id, character-cost, regeneration-count, generation-info, current-concurrent-requests, maximum-concurrent-requests'), (b'history-item-id', b'1BimvLXHU5hbVDPtXgCK'), (b'current-concurrent-requests', b'1'), (b'maximum-concurrent-requests', b'2'), (b'character-cost', b'280'), (b'tts-latency-ms', b'3217'), (b'Content-Length', b'291317'), (b'content-type', b'audio/mpeg'), (b'access-control-allow-origin', b'*'), (b'access-control-allow-headers', b'*'), (b'access-control-allow-methods', b'POST, PATCH, OPTIONS, DELETE, GET, PUT'), (b'access-control-max-age', b'600'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), (b'x-trace-id', b'50b338fcda9cc6435ae5c40f7134f191'), (b'Via', b'1.1 google'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000')])
2025-02-22 19:33:51,851 - httpx - INFO - HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb?output_format=mp3_44100_128 "HTTP/1.1 200 OK"
2025-02-22 19:33:51,851 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-22 19:33:51,900 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-22 19:33:51,900 - httpcore.http11 - DEBUG - response_closed.started
2025-02-22 19:33:51,901 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-22 19:33:51,901 - __main__ - DEBUG - Generated 291317 bytes of audio data
2025-02-22 19:33:51,901 - __main__ - DEBUG - Saving audio to /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp/voiceover_8837405431590281096.mp3
2025-02-22 19:33:51,902 - __main__ - INFO - Voiceover generated and saved successfully
2025-02-22 19:33:51,904 - asyncio - WARNING - Executing <Task finished name='Task-19' coro=<ASGIHTTPConnection.handle_request() done, defined at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/asgi.py:106> result=None created at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 3.909 seconds
2025-02-22 19:33:51,916 - __main__ - INFO - Serving audio file: voiceover_8837405431590281096.mp3
2025-02-22 19:34:36,878 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 19:34:37,390 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:34:37,391 - __main__ - INFO - ElevenLabs API key found
2025-02-22 19:34:37,415 - __main__ - INFO - OpenAI API key found
2025-02-22 19:34:37,431 - __main__ - INFO - Starting Quart application
2025-02-22 19:34:37,431 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 19:34:37,431 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 19:34:37,431 - __main__ - INFO - OpenAI API key present: True
2025-02-22 19:34:37,431 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 19:34:37,431 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 19:34:37,449 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 19:34:37,449 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 19:34:43,809 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 63793): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 63793)>
2025-02-22 19:34:43,811 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 63794): <socket.socket fd=9, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 63794)>
2025-02-22 19:34:43,821 - __main__ - INFO - Serving index page
2025-02-22 19:35:02,549 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 63796): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 63796)>
2025-02-22 19:35:02,555 - __main__ - INFO - Received script generation request
2025-02-22 19:35:02,555 - __main__ - DEBUG - Request data: {'prompt': 'create your dream kitchen with elevenlabs', 'duration': '10'}
2025-02-22 19:35:02,556 - __main__ - INFO - Generating scripts for duration: 10s
2025-02-22 19:35:02,556 - __main__ - INFO - Generating scripts for prompt: create your dream kitchen with elevenlabs... (duration: 10s)
2025-02-22 19:35:02,562 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a professional script writer specializing in voiceovers and commercials. \n                Create engaging, natural-sounding scripts that match the timing constraints perfectly. \n                Each script should be carefully timed where speaking at a natural pace would match the specified duration.'}, {'role': 'user', 'content': "Write 3 different 10-second script variations based on this prompt: create your dream kitchen with elevenlabs\n\n                Requirements:\n                1. Each script must be timed to be spoken in exactly 10 seconds at a natural pace\n                2. Use natural, conversational language\n                3. Make each variation distinct but equally engaging\n                4. Focus on clarity and impact\n                5. Avoid any audio/visual directions - just the spoken words\n                6. Keep the length to no more than 3 sentences.\n                7. Keep sentences short.\n                8. The last sentence should be a call-to-action like 'get your estimate' or 'learn more'.\n\n                Return ONLY the three script variations, separated by ||| (three pipes)."}], 'model': 'gpt-4'}}
2025-02-22 19:35:02,586 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-22 19:35:02,586 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-22 19:35:02,614 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106362120>
2025-02-22 19:35:02,614 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105d7e350> server_hostname='api.openai.com' timeout=5.0
2025-02-22 19:35:02,625 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1063624b0>
2025-02-22 19:35:02,626 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-22 19:35:02,626 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-22 19:35:02,626 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-22 19:35:02,626 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-22 19:35:02,626 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-22 19:35:06,123 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 22 Feb 2025 19:35:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-u65kabkbadcebd8ytdwynb4q'), (b'openai-processing-ms', b'3286'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'39708'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'438ms'), (b'x-request-id', b'req_942065ccf1874987835568dfcf0ae4b3'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=C9qRv4.repy255vhbRlKFyKUrw.bQeOl5gp2QtdkhmA-1740252906-1.0.1.1-kYhkIe_p6hJCyFCZwTl7qbOQF00QE3FyPJTjh5doiYhx1Xz2.yIT6eVXjTrPxIu4n.gvZqRxUTkyWftzFvazmg; path=/; expires=Sat, 22-Feb-25 20:05:06 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=SJqeaH1WzLCvLYb_50i8aNYRf4VDsLNLCIXXxwLiM2w-1740252906132-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91616ac189fb6418-LHR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-22 19:35:06,124 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-22 19:35:06,124 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-22 19:35:06,125 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-22 19:35:06,125 - httpcore.http11 - DEBUG - response_closed.started
2025-02-22 19:35:06,125 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-22 19:35:06,125 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sat, 22 Feb 2025 19:35:06 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-u65kabkbadcebd8ytdwynb4q'), ('openai-processing-ms', '3286'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '40000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '39708'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '438ms'), ('x-request-id', 'req_942065ccf1874987835568dfcf0ae4b3'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=C9qRv4.repy255vhbRlKFyKUrw.bQeOl5gp2QtdkhmA-1740252906-1.0.1.1-kYhkIe_p6hJCyFCZwTl7qbOQF00QE3FyPJTjh5doiYhx1Xz2.yIT6eVXjTrPxIu4n.gvZqRxUTkyWftzFvazmg; path=/; expires=Sat, 22-Feb-25 20:05:06 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=SJqeaH1WzLCvLYb_50i8aNYRf4VDsLNLCIXXxwLiM2w-1740252906132-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '91616ac189fb6418-LHR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-22 19:35:06,126 - openai._base_client - DEBUG - request_id: req_942065ccf1874987835568dfcf0ae4b3
2025-02-22 19:35:06,131 - __main__ - DEBUG - GPT-4 response: "Ever dream of a kitchen that takes your breath away? With Elevenlabs, we make that dream a reality. Get your free estimate now." ||| "Revamp your cooking space with Elevenlabs - a kitchen designed personally, for you. Why wait? Learn more today." ||| "Create your ideal kitchen with Elevenlabs. Turn the heart of your home into a masterpiece. Start your journey with us now."
2025-02-22 19:35:06,131 - __main__ - INFO - Generated 3 script variations
2025-02-22 19:35:06,131 - __main__ - INFO - Scripts generated successfully
2025-02-22 19:35:09,875 - __main__ - INFO - Received voiceover generation request
2025-02-22 19:35:09,875 - __main__ - DEBUG - Request data: {'text': '"Ever dream of a kitchen that takes your breath away? With Elevenlabs, we make that dream a reality. Get your free estimate now."', 'voice': 'wJqPPQ618aTW29mptyoc'}
2025-02-22 19:35:09,876 - __main__ - INFO - Generating voiceover for text: "Ever dream of a kitchen that takes your breath away? With Elevenlabs, we make that dream a reality....
2025-02-22 19:35:09,876 - __main__ - INFO - Using voice ID: wJqPPQ618aTW29mptyoc
2025-02-22 19:35:09,876 - __main__ - DEBUG - Calling ElevenLabs API
2025-02-22 19:35:09,876 - __main__ - DEBUG - Converting audio generator to bytes
2025-02-22 19:35:09,877 - httpcore.connection - DEBUG - connect_tcp.started host='api.elevenlabs.io' port=443 local_address=None timeout=60 socket_options=None
2025-02-22 19:35:09,894 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106363bf0>
2025-02-22 19:35:09,894 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105d7e0d0> server_hostname='api.elevenlabs.io' timeout=60
2025-02-22 19:35:09,910 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106363830>
2025-02-22 19:35:09,910 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-22 19:35:09,911 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-22 19:35:09,911 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-22 19:35:09,911 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-22 19:35:09,911 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-22 19:35:12,046 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Sat, 22 Feb 2025 19:35:09 GMT'), (b'server', b'uvicorn'), (b'request-id', b'UxagX0L5NGthemplAMwi'), (b'access-control-expose-headers', b'request-id, history-item-id, character-cost, regeneration-count, generation-info, current-concurrent-requests, maximum-concurrent-requests'), (b'history-item-id', b'xUAoS7cjhJbAtkkK3m21'), (b'current-concurrent-requests', b'1'), (b'maximum-concurrent-requests', b'2'), (b'character-cost', b'129'), (b'tts-latency-ms', b'1810'), (b'Content-Length', b'160914'), (b'content-type', b'audio/mpeg'), (b'access-control-allow-origin', b'*'), (b'access-control-allow-headers', b'*'), (b'access-control-allow-methods', b'POST, PATCH, OPTIONS, DELETE, GET, PUT'), (b'access-control-max-age', b'600'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), (b'x-trace-id', b'f3fe7eb9d0b280ae5c3f97075709e9c4'), (b'Via', b'1.1 google'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000')])
2025-02-22 19:35:12,047 - httpx - INFO - HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/wJqPPQ618aTW29mptyoc?output_format=mp3_44100_128 "HTTP/1.1 200 OK"
2025-02-22 19:35:12,047 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-22 19:35:12,100 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-22 19:35:12,101 - httpcore.http11 - DEBUG - response_closed.started
2025-02-22 19:35:12,101 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-22 19:35:12,101 - __main__ - DEBUG - Generated 160914 bytes of audio data
2025-02-22 19:35:12,102 - __main__ - DEBUG - Saving audio to /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp/voiceover_7043377993708415111.mp3
2025-02-22 19:35:12,103 - __main__ - INFO - Voiceover generated and saved successfully
2025-02-22 19:35:12,105 - asyncio - WARNING - Executing <Task finished name='Task-27' coro=<ASGIHTTPConnection.handle_request() done, defined at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/asgi.py:106> result=None created at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 2.230 seconds
2025-02-22 19:35:12,110 - __main__ - INFO - Serving audio file: voiceover_7043377993708415111.mp3
2025-02-22 19:35:12,124 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 63802): <socket.socket fd=20, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 63802)>
2025-02-22 19:39:24,484 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 19:39:24,549 - httpcore.connection - DEBUG - close.started
2025-02-22 19:39:24,551 - httpcore.connection - DEBUG - close.complete
2025-02-22 21:53:27,968 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 21:53:27,969 - __main__ - INFO - ElevenLabs API key found
2025-02-22 21:53:28,000 - __main__ - INFO - OpenAI API key found
2025-02-22 21:53:28,016 - __main__ - INFO - Starting Quart application
2025-02-22 21:53:28,016 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 21:53:28,016 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 21:53:28,016 - __main__ - INFO - OpenAI API key present: True
2025-02-22 21:53:28,016 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 21:53:28,016 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 21:53:28,037 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 21:53:28,037 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 22:03:26,843 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 65438): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 65438)>
2025-02-22 22:03:26,845 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 65439): <socket.socket fd=9, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 65439)>
2025-02-22 22:03:26,859 - __main__ - INFO - Serving index page
2025-02-22 22:03:38,644 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 22:03:39,277 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:03:39,278 - __main__ - INFO - ElevenLabs API key found
2025-02-22 22:03:39,308 - __main__ - INFO - OpenAI API key found
2025-02-22 22:03:39,324 - __main__ - INFO - Starting Quart application
2025-02-22 22:03:39,324 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 22:03:39,324 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:03:39,324 - __main__ - INFO - OpenAI API key present: True
2025-02-22 22:03:39,324 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 22:03:39,324 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 22:03:39,344 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 22:03:39,344 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 22:08:07,465 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:08:07,466 - __main__ - INFO - ElevenLabs API key found
2025-02-22 22:08:07,497 - __main__ - INFO - OpenAI API key found
2025-02-22 22:08:07,514 - __main__ - INFO - Starting Quart application
2025-02-22 22:08:07,514 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 22:08:07,514 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:08:07,514 - __main__ - INFO - OpenAI API key present: True
2025-02-22 22:08:07,514 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 22:08:07,514 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 22:08:07,534 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 22:08:07,534 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 22:08:13,211 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49180): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49180)>
2025-02-22 22:08:13,216 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49181): <socket.socket fd=9, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49181)>
2025-02-22 22:08:13,228 - __main__ - INFO - Serving index page
2025-02-22 22:14:19,916 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49240): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49240)>
2025-02-22 22:14:19,922 - __main__ - INFO - Received script generation request
2025-02-22 22:14:19,922 - __main__ - DEBUG - Request data: {'prompt': 'Write a script about a beautiful green kitchen\n', 'duration': '30'}
2025-02-22 22:14:19,922 - __main__ - INFO - Generating scripts for duration: 30s
2025-02-22 22:14:19,923 - __main__ - INFO - Generating scripts for prompt: Write a script about a beautiful green kitchen
... (duration: 30s)
2025-02-22 22:14:19,926 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a professional script writer specializing in voiceovers and commercials. \n                Create engaging, natural-sounding scripts that match the timing constraints perfectly. \n                Each script should be carefully timed where speaking at a natural pace would match the specified duration.'}, {'role': 'user', 'content': "Write 3 different 30-second script variations based on this prompt: Write a script about a beautiful green kitchen\n\n\n                Requirements:\n                1. Each script must be timed to be spoken in exactly 30 seconds at a natural pace\n                2. Use natural, conversational language\n                3. Make each variation distinct but equally engaging\n                4. Focus on clarity and impact\n                5. Avoid any audio/visual directions - just the spoken words\n                6. Keep the length to no more than 3 sentences.\n                7. Keep sentences short.\n                8. The last sentence should be a call-to-action like 'get your estimate' or 'learn more'.\n\n                Return ONLY the three script variations, separated by ||| (three pipes)."}], 'model': 'gpt-4'}}
2025-02-22 22:14:20,007 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-22 22:14:20,008 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-22 22:14:20,070 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11277e5d0>
2025-02-22 22:14:20,071 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x11203a3d0> server_hostname='api.openai.com' timeout=5.0
2025-02-22 22:14:20,118 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x111e772c0>
2025-02-22 22:14:20,119 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-22 22:14:20,119 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-22 22:14:20,119 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-22 22:14:20,120 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-22 22:14:20,120 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-22 22:14:25,170 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 22 Feb 2025 22:14:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-u65kabkbadcebd8ytdwynb4q'), (b'openai-processing-ms', b'4245'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'39706'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'441ms'), (b'x-request-id', b'req_6896b3b37fa761bd5a3dcdab52c653f0'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=yZPIdo94HUmXlUKrysHAoe.2qi2VBbqY_73uGgQ.aUU-1740262465-1.0.1.1-VbDqzkB9FKAg2EsJzQGQitYhpneTS3hSYSR.03B0aBFOEXZTw9ENAIOVX3I1tGfzqrWrRJVbTK55JcdVIb2Chw; path=/; expires=Sat, 22-Feb-25 22:44:25 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=3SrrEIDZxyzKTdFcP8KveC1yTeX_QZgmg0jHxx47bFQ-1740262465217-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'916254181a94ccc9-LHR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-22 22:14:25,173 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-22 22:14:25,173 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-22 22:14:25,174 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-22 22:14:25,174 - httpcore.http11 - DEBUG - response_closed.started
2025-02-22 22:14:25,174 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-22 22:14:25,174 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sat, 22 Feb 2025 22:14:25 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-u65kabkbadcebd8ytdwynb4q'), ('openai-processing-ms', '4245'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '40000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '39706'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '441ms'), ('x-request-id', 'req_6896b3b37fa761bd5a3dcdab52c653f0'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=yZPIdo94HUmXlUKrysHAoe.2qi2VBbqY_73uGgQ.aUU-1740262465-1.0.1.1-VbDqzkB9FKAg2EsJzQGQitYhpneTS3hSYSR.03B0aBFOEXZTw9ENAIOVX3I1tGfzqrWrRJVbTK55JcdVIb2Chw; path=/; expires=Sat, 22-Feb-25 22:44:25 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=3SrrEIDZxyzKTdFcP8KveC1yTeX_QZgmg0jHxx47bFQ-1740262465217-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '916254181a94ccc9-LHR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-22 22:14:25,174 - openai._base_client - DEBUG - request_id: req_6896b3b37fa761bd5a3dcdab52c653f0
2025-02-22 22:14:25,184 - __main__ - DEBUG - GPT-4 response: "Picture a kitchen so welcoming, it brightens your day with just a glimpse. A harmony of vibrant green hues and thoughtful, eco-friendly design. Sounds like a dreamscape? Visit our website to make it your reality today!" ||| "Step into serenity with our stunning green kitchen. Embracing nature's palette, its design uniquely marries style and sustainability. Don't just dream about it, visit our site now and start your journey towards your dream kitchen." ||| "Imagine a sanctuary where fresh ideas bloom -- a kitchen drenched in soothing green. Here, eco-friendly meets elegant. Want this blend of beauty and sustainability? Click our website link to learn more!"
2025-02-22 22:14:25,184 - __main__ - INFO - Generated 3 script variations
2025-02-22 22:14:25,184 - __main__ - INFO - Scripts generated successfully
2025-02-22 22:14:38,959 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49247): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49247)>
2025-02-22 22:14:38,964 - __main__ - INFO - Received voiceover generation request
2025-02-22 22:14:38,964 - __main__ - DEBUG - Request data: {'text': 'Imagine a sanctuary where fresh ideas bloom -- a kitchen drenched in soothing green. Here, eco-friendly meets elegant. Want this blend of beauty and sustainability? Click our website link to learn more!', 'voice': 'wJqPPQ618aTW29mptyoc', 'video_path': 'http://127.0.0.1:5001/917644d9-471c-4a8f-b9bd-831063e27b01', 'duration': 30}
2025-02-22 22:14:38,964 - __main__ - INFO - Generating voiceover for text: Imagine a sanctuary where fresh ideas bloom -- a kitchen drenched in soothing green. Here, eco-frien...
2025-02-22 22:14:38,964 - __main__ - INFO - Using voice ID: wJqPPQ618aTW29mptyoc
2025-02-22 22:14:38,964 - __main__ - DEBUG - Calling ElevenLabs API
2025-02-22 22:14:38,965 - __main__ - DEBUG - Converting audio generator to bytes
2025-02-22 22:14:38,966 - httpcore.connection - DEBUG - connect_tcp.started host='api.elevenlabs.io' port=443 local_address=None timeout=60 socket_options=None
2025-02-22 22:14:39,004 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11277fa70>
2025-02-22 22:14:39,004 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x11203a150> server_hostname='api.elevenlabs.io' timeout=60
2025-02-22 22:14:39,026 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11277dc10>
2025-02-22 22:14:39,027 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-22 22:14:39,028 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-22 22:14:39,028 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-22 22:14:39,028 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-22 22:14:39,028 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-22 22:14:43,222 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'date', b'Sat, 22 Feb 2025 22:14:38 GMT'), (b'server', b'uvicorn'), (b'Content-Length', b'164'), (b'content-type', b'application/json'), (b'access-control-allow-origin', b'*'), (b'access-control-allow-headers', b'*'), (b'access-control-allow-methods', b'POST, PATCH, OPTIONS, DELETE, GET, PUT'), (b'access-control-max-age', b'600'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), (b'x-trace-id', b'b769bbed069c03eb49b93877517b9fbe'), (b'Via', b'1.1 google'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000')])
2025-02-22 22:14:43,224 - httpx - INFO - HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/wJqPPQ618aTW29mptyoc?output_format=mp3_44100_128 "HTTP/1.1 429 Too Many Requests"
2025-02-22 22:14:43,224 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-22 22:14:43,224 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-22 22:14:43,225 - httpcore.http11 - DEBUG - response_closed.started
2025-02-22 22:14:43,225 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-22 22:14:43,225 - __main__ - ERROR - Error generating voiceover and video:
2025-02-22 22:14:43,228 - __main__ - ERROR - Traceback (most recent call last):
  File "/Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/voiceover_test.py", line 564, in generate
    for chunk in audio:
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/elevenlabs/text_to_speech/client.py", line 201, in convert
    raise ApiError(status_code=_response.status_code, body=_response_json)
elevenlabs.core.api_error.ApiError: status_code: 429, body: {'detail': {'status': 'system_busy', 'message': 'We are sorry, the system is experiencing heavy traffic, please try again. Higher subscriptions have higher priority.'}}

2025-02-22 22:14:43,231 - asyncio - WARNING - Executing <Task finished name='Task-31' coro=<ASGIHTTPConnection.handle_request() done, defined at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/asgi.py:106> result=None created at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 4.268 seconds
2025-02-22 22:18:50,555 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 22:18:51,326 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:18:51,327 - __main__ - INFO - ElevenLabs API key found
2025-02-22 22:18:51,357 - __main__ - INFO - OpenAI API key found
2025-02-22 22:18:51,373 - __main__ - INFO - Starting Quart application
2025-02-22 22:18:51,373 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 22:18:51,373 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:18:51,373 - __main__ - INFO - OpenAI API key present: True
2025-02-22 22:18:51,373 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 22:18:51,373 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 22:18:51,393 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 22:18:51,393 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 22:19:07,735 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 22:19:08,319 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:19:08,319 - __main__ - INFO - ElevenLabs API key found
2025-02-22 22:19:08,344 - __main__ - INFO - OpenAI API key found
2025-02-22 22:19:08,360 - __main__ - INFO - Starting Quart application
2025-02-22 22:19:08,360 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 22:19:08,360 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:19:08,360 - __main__ - INFO - OpenAI API key present: True
2025-02-22 22:19:08,360 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 22:19:08,361 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 22:19:08,378 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 22:19:08,379 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 22:19:32,623 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49373): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49373)>
2025-02-22 22:19:32,625 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49374): <socket.socket fd=9, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49374)>
2025-02-22 22:19:32,639 - __main__ - INFO - Serving index page
2025-02-22 22:19:43,484 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49375): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49375)>
2025-02-22 22:19:43,488 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:19:43,491 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:19:43,494 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:19:43,495 - __main__ - INFO - Received video upload request
2025-02-22 22:19:43,496 - __main__ - ERROR - Error processing video upload:
2025-02-22 22:19:43,498 - __main__ - ERROR - Traceback (most recent call last):
  File "/Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/voiceover_test.py", line 795, in upload_video
    if 'video' not in (await request.files):
                       ^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/wrappers/request.py", line 326, in files
    await self._load_form_data()
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/wrappers/request.py", line 342, in _load_form_data
    self._form, self._files = await asyncio.wait_for(
                              ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py", line 520, in wait_for
    return await fut
           ^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/formparser.py", line 80, in parse
    return await parse_func(self, body, mimetype, content_length, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/formparser.py", line 107, in _parse_multipart
    return await parser.parse(body, boundary, content_length)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/formparser.py", line 201, in parse
    async for data in body:
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/wrappers/request.py", line 74, in __anext__
    raise self._must_raise
werkzeug.exceptions.RequestEntityTooLarge: 413 Request Entity Too Large: The data value transmitted exceeds the capacity limit.

2025-02-22 22:19:59,390 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49381): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49381)>
2025-02-22 22:19:59,400 - __main__ - INFO - Received script generation request
2025-02-22 22:19:59,401 - __main__ - DEBUG - Request data: {'prompt': 'write a script about a beautiful green kitchen renovation', 'duration': '30'}
2025-02-22 22:19:59,401 - __main__ - INFO - Generating scripts for duration: 30s
2025-02-22 22:19:59,401 - __main__ - INFO - Generating scripts for prompt: write a script about a beautiful green kitchen renovation... (duration: 30s)
2025-02-22 22:19:59,405 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a professional script writer specializing in voiceovers and commercials. \n                Create engaging, natural-sounding scripts that match the timing constraints perfectly. \n                Each script should be carefully timed where speaking at a natural pace would match the specified duration.'}, {'role': 'user', 'content': "Write 3 different 30-second script variations based on this prompt: write a script about a beautiful green kitchen renovation\n\n                Requirements:\n                1. Each script must be timed to be spoken in exactly 30 seconds at a natural pace\n                2. Use natural, conversational language\n                3. Make each variation distinct but equally engaging\n                4. Focus on clarity and impact\n                5. Avoid any audio/visual directions - just the spoken words\n                6. Keep the length to no more than 3 sentences.\n                7. Keep sentences short.\n                8. The last sentence should be a call-to-action like 'get your estimate' or 'learn more'.\n\n                Return ONLY the three script variations, separated by ||| (three pipes)."}], 'model': 'gpt-4'}}
2025-02-22 22:19:59,431 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-22 22:19:59,431 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-22 22:19:59,481 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11378e330>
2025-02-22 22:19:59,482 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1133ca3d0> server_hostname='api.openai.com' timeout=5.0
2025-02-22 22:19:59,512 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11332c530>
2025-02-22 22:19:59,512 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-22 22:19:59,513 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-22 22:19:59,513 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-22 22:19:59,513 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-22 22:19:59,513 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-22 22:20:05,058 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 22 Feb 2025 22:20:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-u65kabkbadcebd8ytdwynb4q'), (b'openai-processing-ms', b'5322'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'39704'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'444ms'), (b'x-request-id', b'req_13457058a2cc8ae58953945defa013bd'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=9jUy6RWCXMFdSR08hm9Sp3Wr.H5jRO3lYEVmOw1lzUo-1740262805-1.0.1.1-E3hlMp2xbcTyXzk0rbSOCmex274KL2QIKQhx4lbey_2NZla2O0EksvqLdmGlVzs3m0HcV3GnT5tfyNg.xRsQmw; path=/; expires=Sat, 22-Feb-25 22:50:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=BVBHPJtt3d7HU5FRpkwdSIKm.snHYfwz3RcaFTcyEp0-1740262805105-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91625c614b39bda0-LHR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-22 22:20:05,061 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-22 22:20:05,061 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-22 22:20:05,062 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-22 22:20:05,062 - httpcore.http11 - DEBUG - response_closed.started
2025-02-22 22:20:05,062 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-22 22:20:05,062 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sat, 22 Feb 2025 22:20:05 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-u65kabkbadcebd8ytdwynb4q'), ('openai-processing-ms', '5322'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '40000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '39704'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '444ms'), ('x-request-id', 'req_13457058a2cc8ae58953945defa013bd'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=9jUy6RWCXMFdSR08hm9Sp3Wr.H5jRO3lYEVmOw1lzUo-1740262805-1.0.1.1-E3hlMp2xbcTyXzk0rbSOCmex274KL2QIKQhx4lbey_2NZla2O0EksvqLdmGlVzs3m0HcV3GnT5tfyNg.xRsQmw; path=/; expires=Sat, 22-Feb-25 22:50:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=BVBHPJtt3d7HU5FRpkwdSIKm.snHYfwz3RcaFTcyEp0-1740262805105-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '91625c614b39bda0-LHR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-22 22:20:05,062 - openai._base_client - DEBUG - request_id: req_13457058a2cc8ae58953945defa013bd
2025-02-22 22:20:05,069 - __main__ - DEBUG - GPT-4 response: 1. "Imagine your dream kitchen, with lush green cabinets and sparkling granite countertops. Our team at Green Haven Renovations transforms tired-looking kitchens into stunning masterpieces. Don't wait any longer, call us today and get your free estimate."
|||
2. "Ever thought about waking up to a fresh, green kitchen? At Green Oasis Renovations, we make this possible by giving your kitchen a nature-inspired makeover. Act now, discover the kitchen you deserve, and request your quote!"
|||
3. "Ready for a kitchen that's as fresh as a spring morning? Let's turn your kitchen into a vibrant, green haven with our unique renovation services. Be bold, embrace the transformation - reach out now to learn more!"
2025-02-22 22:20:05,069 - __main__ - INFO - Generated 3 script variations
2025-02-22 22:20:05,069 - __main__ - INFO - Scripts generated successfully
2025-02-22 22:21:14,491 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49393): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49393)>
2025-02-22 22:21:14,497 - __main__ - INFO - Received voiceover generation request
2025-02-22 22:21:14,498 - __main__ - DEBUG - Request data: {'text': '3. "Ready for a kitchen that\'s as fresh as a spring morning? Let\'s turn your kitchen into a vibrant, green haven with our unique renovation services. Be bold, embrace the transformation - reach out now to learn more!"', 'voice': 'wJqPPQ618aTW29mptyoc'}
2025-02-22 22:21:14,498 - __main__ - WARNING - No video path provided
2025-02-22 22:22:15,425 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 22:22:15,953 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:22:15,954 - __main__ - INFO - ElevenLabs API key found
2025-02-22 22:22:15,979 - __main__ - INFO - OpenAI API key found
2025-02-22 22:22:15,995 - __main__ - INFO - Starting Quart application
2025-02-22 22:22:15,995 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 22:22:15,995 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:22:15,995 - __main__ - INFO - OpenAI API key present: True
2025-02-22 22:22:15,995 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 22:22:15,996 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 22:22:16,014 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 22:22:16,014 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 22:22:17,016 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 22:22:17,513 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:22:17,514 - __main__ - INFO - ElevenLabs API key found
2025-02-22 22:22:17,539 - __main__ - INFO - OpenAI API key found
2025-02-22 22:22:17,555 - __main__ - INFO - Starting Quart application
2025-02-22 22:22:17,555 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 22:22:17,555 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:22:17,555 - __main__ - INFO - OpenAI API key present: True
2025-02-22 22:22:17,555 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 22:22:17,556 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 22:22:17,573 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 22:22:17,573 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 22:22:28,467 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49423): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49423)>
2025-02-22 22:22:28,468 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49424): <socket.socket fd=9, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49424)>
2025-02-22 22:22:28,483 - __main__ - INFO - Serving index page
2025-02-22 22:22:50,495 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49429): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49429)>
2025-02-22 22:22:50,503 - __main__ - INFO - Received script generation request
2025-02-22 22:22:50,503 - __main__ - DEBUG - Request data: {'prompt': 'A beautiful green kitchen renovation. Get your estimate today', 'duration': '30'}
2025-02-22 22:22:50,503 - __main__ - INFO - Generating scripts for duration: 30s
2025-02-22 22:22:50,503 - __main__ - INFO - Generating scripts for prompt: A beautiful green kitchen renovation. Get your estimate today... (duration: 30s)
2025-02-22 22:22:50,509 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a professional script writer specializing in voiceovers and commercials. \n                Create engaging, natural-sounding scripts that match the timing constraints perfectly. \n                Each script should be carefully timed where speaking at a natural pace would match the specified duration.'}, {'role': 'user', 'content': "Write 3 different 30-second script variations based on this prompt: A beautiful green kitchen renovation. Get your estimate today\n\n                Requirements:\n                1. Each script must be timed to be spoken in exactly 30 seconds at a natural pace\n                2. Use natural, conversational language\n                3. Make each variation distinct but equally engaging\n                4. Focus on clarity and impact\n                5. Avoid any audio/visual directions - just the spoken words\n                6. Keep the length to no more than 3 sentences.\n                7. Keep sentences short.\n                8. The last sentence should be a call-to-action like 'get your estimate' or 'learn more'.\n\n                Return ONLY the three script variations, separated by ||| (three pipes)."}], 'model': 'gpt-4'}}
2025-02-22 22:22:50,534 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-22 22:22:50,534 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-22 22:22:50,554 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11655fd10>
2025-02-22 22:22:50,554 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110dd24d0> server_hostname='api.openai.com' timeout=5.0
2025-02-22 22:22:50,565 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11655e990>
2025-02-22 22:22:50,566 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-22 22:22:50,566 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-22 22:22:50,566 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-22 22:22:50,566 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-22 22:22:50,566 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-22 22:22:55,700 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 22 Feb 2025 22:22:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-u65kabkbadcebd8ytdwynb4q'), (b'openai-processing-ms', b'4678'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'39703'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'445ms'), (b'x-request-id', b'req_ca7dfc09ea477feabdd0e6778f3e884b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=QB58tZrPBO3Qj7wQe1dJqpybxikBG8Qq6COzrlj9yT8-1740262975-1.0.1.1-ZeT9gS2jVPZzyxT77OPUkkFF8D90PtgQR9CsajUtlp4ea_ESIbvceRSmlN4N9_._CGvMuYd3SCb5L_9wYWhk3A; path=/; expires=Sat, 22-Feb-25 22:52:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=d6fDWu1K9LgKtZiEZa1DaHVsCVm6SJhkhf8Po6UaQEY-1740262975749-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9162608e68559db6-LHR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-22 22:22:55,702 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-22 22:22:55,703 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-22 22:22:55,709 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-22 22:22:55,710 - httpcore.http11 - DEBUG - response_closed.started
2025-02-22 22:22:55,710 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-22 22:22:55,712 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sat, 22 Feb 2025 22:22:55 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-u65kabkbadcebd8ytdwynb4q'), ('openai-processing-ms', '4678'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '40000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '39703'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '445ms'), ('x-request-id', 'req_ca7dfc09ea477feabdd0e6778f3e884b'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=QB58tZrPBO3Qj7wQe1dJqpybxikBG8Qq6COzrlj9yT8-1740262975-1.0.1.1-ZeT9gS2jVPZzyxT77OPUkkFF8D90PtgQR9CsajUtlp4ea_ESIbvceRSmlN4N9_._CGvMuYd3SCb5L_9wYWhk3A; path=/; expires=Sat, 22-Feb-25 22:52:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=d6fDWu1K9LgKtZiEZa1DaHVsCVm6SJhkhf8Po6UaQEY-1740262975749-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9162608e68559db6-LHR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-22 22:22:55,714 - openai._base_client - DEBUG - request_id: req_ca7dfc09ea477feabdd0e6778f3e884b
2025-02-22 22:22:55,723 - __main__ - DEBUG - GPT-4 response: 1. Picture a kitchen that’s a conversation starter. Vibrant green cabinets, space-maximizing design, and stunning, eco-friendly finishes. Dare to be extraordinary? Get your personalized green kitchen estimate today.

|||

2. What’s cooking in your dream kitchen? Gorgeous green hues, a hint of rustic charm and timeless appeal. Isn't it time your kitchen reflected your style? Visit our website now and get your free renovation estimate. 

|||

3. Say goodbye to tired countertops and outdated cabinets. Say hello to eye-catching green elegance that revitalizes your cooking space. Ready for a kitchen makeover? Secure your renovation estimate today.
2025-02-22 22:22:55,723 - __main__ - INFO - Generated 3 script variations
2025-02-22 22:22:55,723 - __main__ - INFO - Scripts generated successfully
2025-02-22 22:23:19,844 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49433): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49433)>
2025-02-22 22:23:19,849 - __main__ - INFO - Received voiceover generation request
2025-02-22 22:23:19,849 - __main__ - DEBUG - Request data: {'text': 'Say goodbye to tired countertops and outdated cabinets. Say hello to eye-catching elegance that revitalizes your cooking space. Get your free renovation estimate today.', 'voice': 'wJqPPQ618aTW29mptyoc'}
2025-02-22 22:23:19,849 - __main__ - INFO - Generating voiceover for text: Say goodbye to tired countertops and outdated cabinets. Say hello to eye-catching elegance that revi...
2025-02-22 22:23:19,849 - __main__ - INFO - Using voice ID: wJqPPQ618aTW29mptyoc
2025-02-22 22:23:19,849 - __main__ - DEBUG - Calling ElevenLabs API
2025-02-22 22:23:19,849 - __main__ - DEBUG - Converting audio generator to bytes
2025-02-22 22:23:19,851 - httpcore.connection - DEBUG - connect_tcp.started host='api.elevenlabs.io' port=443 local_address=None timeout=60 socket_options=None
2025-02-22 22:23:19,869 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116589580>
2025-02-22 22:23:19,869 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110dd2250> server_hostname='api.elevenlabs.io' timeout=60
2025-02-22 22:23:19,879 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116589220>
2025-02-22 22:23:19,879 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-22 22:23:19,879 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-22 22:23:19,879 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-22 22:23:19,879 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-22 22:23:19,879 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-22 22:23:23,022 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Sat, 22 Feb 2025 22:23:19 GMT'), (b'server', b'uvicorn'), (b'request-id', b'tDqiHei4Y2TmDPNbmwD4'), (b'access-control-expose-headers', b'request-id, history-item-id, character-cost, regeneration-count, generation-info, current-concurrent-requests, maximum-concurrent-requests'), (b'history-item-id', b'yOkCjirCVVGnqOn8gCLb'), (b'current-concurrent-requests', b'1'), (b'maximum-concurrent-requests', b'5'), (b'character-cost', b'168'), (b'tts-latency-ms', b'2634'), (b'Content-Length', b'224444'), (b'content-type', b'audio/mpeg'), (b'access-control-allow-origin', b'*'), (b'access-control-allow-headers', b'*'), (b'access-control-allow-methods', b'POST, PATCH, OPTIONS, DELETE, GET, PUT'), (b'access-control-max-age', b'600'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), (b'x-trace-id', b'd08423d698c971d9f13193dd5a83ae6e'), (b'Via', b'1.1 google'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000')])
2025-02-22 22:23:23,023 - httpx - INFO - HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/wJqPPQ618aTW29mptyoc?output_format=mp3_44100_128 "HTTP/1.1 200 OK"
2025-02-22 22:23:23,024 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-22 22:23:23,096 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-22 22:23:23,097 - httpcore.http11 - DEBUG - response_closed.started
2025-02-22 22:23:23,097 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-22 22:23:23,097 - __main__ - DEBUG - Generated 224444 bytes of audio data
2025-02-22 22:23:23,097 - __main__ - DEBUG - Saving audio to /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp/voiceover_1735690037003340218.mp3
2025-02-22 22:23:23,098 - __main__ - INFO - Voiceover generated successfully
2025-02-22 22:23:23,101 - asyncio - WARNING - Executing <Task finished name='Task-31' coro=<ASGIHTTPConnection.handle_request() done, defined at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/asgi.py:106> result=None created at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 3.252 seconds
2025-02-22 22:23:23,107 - __main__ - INFO - Serving audio file: voiceover_1735690037003340218.mp3
2025-02-22 22:23:23,131 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49435): <socket.socket fd=17, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49435)>
2025-02-22 22:23:57,616 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49443): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49443)>
2025-02-22 22:23:57,622 - __main__ - INFO - Received voiceover generation request
2025-02-22 22:23:57,622 - __main__ - DEBUG - Request data: {'text': 'Say goodbye to your tired countertops. Say hello to eye-catching elegance that revitalizes your cooking space. Get your free renovation estimate today.', 'voice': 'wJqPPQ618aTW29mptyoc'}
2025-02-22 22:23:57,622 - __main__ - INFO - Generating voiceover for text: Say goodbye to your tired countertops. Say hello to eye-catching elegance that revitalizes your cook...
2025-02-22 22:23:57,623 - __main__ - INFO - Using voice ID: wJqPPQ618aTW29mptyoc
2025-02-22 22:23:57,623 - __main__ - DEBUG - Calling ElevenLabs API
2025-02-22 22:23:57,623 - __main__ - DEBUG - Converting audio generator to bytes
2025-02-22 22:23:57,625 - httpcore.connection - DEBUG - close.started
2025-02-22 22:23:57,627 - httpcore.connection - DEBUG - close.complete
2025-02-22 22:23:57,627 - httpcore.connection - DEBUG - connect_tcp.started host='api.elevenlabs.io' port=443 local_address=None timeout=60 socket_options=None
2025-02-22 22:23:57,634 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116588d40>
2025-02-22 22:23:57,634 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110dd2250> server_hostname='api.elevenlabs.io' timeout=60
2025-02-22 22:23:57,647 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116589bb0>
2025-02-22 22:23:57,647 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-22 22:23:57,647 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-22 22:23:57,647 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-22 22:23:57,647 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-22 22:23:57,647 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-22 22:24:00,306 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Sat, 22 Feb 2025 22:23:57 GMT'), (b'server', b'uvicorn'), (b'request-id', b'LrPrbhLUoEBecK8HL4DG'), (b'access-control-expose-headers', b'request-id, history-item-id, character-cost, regeneration-count, generation-info, current-concurrent-requests, maximum-concurrent-requests'), (b'history-item-id', b'GdLSgdTzsfilSUucQ092'), (b'current-concurrent-requests', b'1'), (b'maximum-concurrent-requests', b'5'), (b'character-cost', b'151'), (b'tts-latency-ms', b'2205'), (b'Content-Length', b'198948'), (b'content-type', b'audio/mpeg'), (b'access-control-allow-origin', b'*'), (b'access-control-allow-headers', b'*'), (b'access-control-allow-methods', b'POST, PATCH, OPTIONS, DELETE, GET, PUT'), (b'access-control-max-age', b'600'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), (b'x-trace-id', b'60b33e4f0584e77b33588fb77f7595a8'), (b'Via', b'1.1 google'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000')])
2025-02-22 22:24:00,308 - httpx - INFO - HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/wJqPPQ618aTW29mptyoc?output_format=mp3_44100_128 "HTTP/1.1 200 OK"
2025-02-22 22:24:00,308 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-22 22:24:00,386 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-22 22:24:00,386 - httpcore.http11 - DEBUG - response_closed.started
2025-02-22 22:24:00,387 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-22 22:24:00,387 - __main__ - DEBUG - Generated 198948 bytes of audio data
2025-02-22 22:24:00,387 - __main__ - DEBUG - Saving audio to /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp/voiceover_5654593571951400601.mp3
2025-02-22 22:24:00,388 - __main__ - INFO - Voiceover generated successfully
2025-02-22 22:24:00,390 - asyncio - WARNING - Executing <Task finished name='Task-51' coro=<ASGIHTTPConnection.handle_request() done, defined at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/asgi.py:106> result=None created at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 2.768 seconds
2025-02-22 22:24:00,408 - __main__ - INFO - Serving audio file: voiceover_5654593571951400601.mp3
2025-02-22 22:25:40,170 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49463): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49463)>
2025-02-22 22:25:40,175 - __main__ - INFO - Received voiceover generation request
2025-02-22 22:25:40,176 - __main__ - DEBUG - Request data: {'text': 'Say goodbye to your tired countertops. Say hello to eye-catching elegance. Get your free renovation estimate today.', 'voice': 'wJqPPQ618aTW29mptyoc'}
2025-02-22 22:25:40,176 - __main__ - INFO - Generating voiceover for text: Say goodbye to your tired countertops. Say hello to eye-catching elegance. Get your free renovation ...
2025-02-22 22:25:40,176 - __main__ - INFO - Using voice ID: wJqPPQ618aTW29mptyoc
2025-02-22 22:25:40,177 - __main__ - DEBUG - Calling ElevenLabs API
2025-02-22 22:25:40,178 - __main__ - DEBUG - Converting audio generator to bytes
2025-02-22 22:25:40,179 - httpcore.connection - DEBUG - close.started
2025-02-22 22:25:40,179 - httpcore.connection - DEBUG - close.complete
2025-02-22 22:25:40,179 - httpcore.connection - DEBUG - connect_tcp.started host='api.elevenlabs.io' port=443 local_address=None timeout=60 socket_options=None
2025-02-22 22:25:40,207 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1165fc170>
2025-02-22 22:25:40,207 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110dd2250> server_hostname='api.elevenlabs.io' timeout=60
2025-02-22 22:25:40,221 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11658be30>
2025-02-22 22:25:40,221 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-22 22:25:40,221 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-22 22:25:40,221 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-22 22:25:40,222 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-22 22:25:40,222 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-22 22:25:42,337 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Sat, 22 Feb 2025 22:25:39 GMT'), (b'server', b'uvicorn'), (b'request-id', b'3ofeUJ9YuW0zrBVhInim'), (b'access-control-expose-headers', b'request-id, history-item-id, character-cost, regeneration-count, generation-info, current-concurrent-requests, maximum-concurrent-requests'), (b'history-item-id', b'caFkTA8haerXLQneYw7m'), (b'current-concurrent-requests', b'1'), (b'maximum-concurrent-requests', b'5'), (b'character-cost', b'115'), (b'tts-latency-ms', b'1747'), (b'Content-Length', b'145449'), (b'content-type', b'audio/mpeg'), (b'access-control-allow-origin', b'*'), (b'access-control-allow-headers', b'*'), (b'access-control-allow-methods', b'POST, PATCH, OPTIONS, DELETE, GET, PUT'), (b'access-control-max-age', b'600'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), (b'x-trace-id', b'2ce77fcf5958f3eae18bfcaf6abecee8'), (b'Via', b'1.1 google'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000')])
2025-02-22 22:25:42,338 - httpx - INFO - HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/wJqPPQ618aTW29mptyoc?output_format=mp3_44100_128 "HTTP/1.1 200 OK"
2025-02-22 22:25:42,339 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-22 22:25:42,399 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-22 22:25:42,400 - httpcore.http11 - DEBUG - response_closed.started
2025-02-22 22:25:42,400 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-22 22:25:42,400 - __main__ - DEBUG - Generated 145449 bytes of audio data
2025-02-22 22:25:42,400 - __main__ - DEBUG - Saving audio to /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp/voiceover_1248784413594736839.mp3
2025-02-22 22:25:42,401 - __main__ - INFO - Voiceover generated successfully
2025-02-22 22:25:42,403 - asyncio - WARNING - Executing <Task finished name='Task-63' coro=<ASGIHTTPConnection.handle_request() done, defined at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/asgi.py:106> result=None created at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 2.228 seconds
2025-02-22 22:25:42,415 - __main__ - INFO - Serving audio file: voiceover_1248784413594736839.mp3
2025-02-22 22:25:54,666 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49471): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49471)>
2025-02-22 22:25:54,672 - __main__ - INFO - Received video combination request
2025-02-22 22:25:54,673 - __main__ - DEBUG - Request data: {'video_path': 'http://127.0.0.1:5001/f321a595-9e26-4c49-9940-7868ea030169', 'audio_url': '/api/audio/voiceover_1248784413594736839.mp3', 'text': 'Say goodbye to your tired countertops. Say hello to eye-catching elegance. Get your free renovation estimate today.', 'duration': 30}
2025-02-22 22:25:54,673 - __main__ - INFO - Generating subtitles...
2025-02-22 22:25:54,673 - __main__ - INFO - Generating SRT subtitles for text: Say goodbye to your tired countertops. Say hello to eye-catching elegance. Get your free renovation ...
2025-02-22 22:25:54,673 - __main__ - DEBUG - Saving subtitles to /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp/subtitles_8919420811423797956.srt
2025-02-22 22:25:54,674 - __main__ - INFO - Subtitles generated successfully
2025-02-22 22:25:54,674 - __main__ - INFO - Combining video, audio and subtitles...
2025-02-22 22:25:54,675 - __main__ - INFO - Combining video, audio and subtitles...
2025-02-22 22:25:54,676 - asyncio - DEBUG - execute program 'ffmpeg' stdout=<pipe> stderr=<pipe>
2025-02-22 22:25:54,689 - asyncio - DEBUG - process 'ffmpeg' created: pid 88618
2025-02-22 22:25:54,692 - asyncio - DEBUG - Read pipe 16 connected: (<_UnixReadPipeTransport fd=16 polling>, <ReadSubprocessPipeProto fd=1 pipe=<_UnixReadPipeTransport fd=16 polling>>)
2025-02-22 22:25:54,692 - asyncio - DEBUG - Read pipe 18 connected: (<_UnixReadPipeTransport fd=18 polling>, <ReadSubprocessPipeProto fd=2 pipe=<_UnixReadPipeTransport fd=18 polling>>)
2025-02-22 22:25:54,693 - asyncio - INFO - execute program 'ffmpeg': <_UnixSubprocessTransport pid=88618 running stdout=<_UnixReadPipeTransport fd=16 polling> stderr=<_UnixReadPipeTransport fd=18 polling>>
2025-02-22 22:25:54,693 - asyncio - DEBUG - <Process 88618> communicate: read stdout
2025-02-22 22:25:54,694 - asyncio - DEBUG - <Process 88618> communicate: read stderr
2025-02-22 22:26:05,261 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49473): <socket.socket fd=17, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49473)>
2025-02-22 22:26:05,265 - asyncio - INFO - <_UnixReadPipeTransport fd=18 polling> was closed by peer
2025-02-22 22:26:05,265 - asyncio - DEBUG - process 88618 exited with returncode 8
2025-02-22 22:26:05,266 - asyncio - INFO - <_UnixReadPipeTransport fd=16 polling> was closed by peer
2025-02-22 22:26:05,266 - asyncio - INFO - <_UnixSubprocessTransport pid=88618 running stdout=<_UnixReadPipeTransport closed fd=16 closed> stderr=<_UnixReadPipeTransport closed fd=18 closed>> exited with return code 8
2025-02-22 22:26:05,266 - asyncio - DEBUG - <Process 88618> communicate: close stderr
2025-02-22 22:26:05,266 - asyncio - DEBUG - <Process 88618> communicate: close stdout
2025-02-22 22:26:05,267 - __main__ - ERROR - FFmpeg error: ffmpeg version 7.1 Copyright (c) 2000-2024 the FFmpeg developers
  built with Apple clang version 16.0.0 (clang-1600.0.26.4)
  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon
  libavutil      59. 39.100 / 59. 39.100
  libavcodec     61. 19.100 / 61. 19.100
  libavformat    61.  7.100 / 61.  7.100
  libavdevice    61.  3.100 / 61.  3.100
  libavfilter    10.  4.100 / 10.  4.100
  libswscale      8.  3.100 /  8.  3.100
  libswresample   5.  3.100 /  5.  3.100
  libpostproc    58.  3.100 / 58.  3.100
[http @ 0x15b633150] HTTP error 404 
[in#0 @ 0x15b632b70] Error opening input: Server returned 404 Not Found
Error opening input file http://127.0.0.1:5001/f321a595-9e26-4c49-9940-7868ea030169.
Error opening input files: Server returned 404 Not Found

2025-02-22 22:26:05,267 - __main__ - ERROR - Error combining video, audio and subtitles: FFmpeg error: ffmpeg version 7.1 Copyright (c) 2000-2024 the FFmpeg developers
  built with Apple clang version 16.0.0 (clang-1600.0.26.4)
  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon
  libavutil      59. 39.100 / 59. 39.100
  libavcodec     61. 19.100 / 61. 19.100
  libavformat    61.  7.100 / 61.  7.100
  libavdevice    61.  3.100 / 61.  3.100
  libavfilter    10.  4.100 / 10.  4.100
  libswscale      8.  3.100 /  8.  3.100
  libswresample   5.  3.100 /  5.  3.100
  libpostproc    58.  3.100 / 58.  3.100
[http @ 0x15b633150] HTTP error 404 
[in#0 @ 0x15b632b70] Error opening input: Server returned 404 Not Found
Error opening input file http://127.0.0.1:5001/f321a595-9e26-4c49-9940-7868ea030169.
Error opening input files: Server returned 404 Not Found

2025-02-22 22:26:05,267 - __main__ - ERROR - Traceback (most recent call last):
  File "/Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/voiceover_test.py", line 962, in combine_video_audio_subtitles
    raise Exception(f"FFmpeg error: {stderr.decode()}")
Exception: FFmpeg error: ffmpeg version 7.1 Copyright (c) 2000-2024 the FFmpeg developers
  built with Apple clang version 16.0.0 (clang-1600.0.26.4)
  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon
  libavutil      59. 39.100 / 59. 39.100
  libavcodec     61. 19.100 / 61. 19.100
  libavformat    61.  7.100 / 61.  7.100
  libavdevice    61.  3.100 / 61.  3.100
  libavfilter    10.  4.100 / 10.  4.100
  libswscale      8.  3.100 /  8.  3.100
  libswresample   5.  3.100 /  5.  3.100
  libpostproc    58.  3.100 / 58.  3.100
[http @ 0x15b633150] HTTP error 404 
[in#0 @ 0x15b632b70] Error opening input: Server returned 404 Not Found
Error opening input file http://127.0.0.1:5001/f321a595-9e26-4c49-9940-7868ea030169.
Error opening input files: Server returned 404 Not Found


2025-02-22 22:26:05,267 - __main__ - ERROR - Error combining video:
2025-02-22 22:26:05,268 - __main__ - ERROR - Traceback (most recent call last):
  File "/Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/voiceover_test.py", line 1013, in combine
    final_video_path = await combine_video_audio_subtitles(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/voiceover_test.py", line 962, in combine_video_audio_subtitles
    raise Exception(f"FFmpeg error: {stderr.decode()}")
Exception: FFmpeg error: ffmpeg version 7.1 Copyright (c) 2000-2024 the FFmpeg developers
  built with Apple clang version 16.0.0 (clang-1600.0.26.4)
  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon
  libavutil      59. 39.100 / 59. 39.100
  libavcodec     61. 19.100 / 61. 19.100
  libavformat    61.  7.100 / 61.  7.100
  libavdevice    61.  3.100 / 61.  3.100
  libavfilter    10.  4.100 / 10.  4.100
  libswscale      8.  3.100 /  8.  3.100
  libswresample   5.  3.100 /  5.  3.100
  libpostproc    58.  3.100 / 58.  3.100
[http @ 0x15b633150] HTTP error 404 
[in#0 @ 0x15b632b70] Error opening input: Server returned 404 Not Found
Error opening input file http://127.0.0.1:5001/f321a595-9e26-4c49-9940-7868ea030169.
Error opening input files: Server returned 404 Not Found


2025-02-22 22:29:28,270 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 22:29:28,804 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:29:28,805 - __main__ - INFO - ElevenLabs API key found
2025-02-22 22:29:28,830 - __main__ - INFO - OpenAI API key found
2025-02-22 22:29:28,847 - __main__ - INFO - Starting Quart application
2025-02-22 22:29:28,847 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 22:29:28,847 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:29:28,847 - __main__ - INFO - OpenAI API key present: True
2025-02-22 22:29:28,847 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 22:29:28,847 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 22:29:28,865 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 22:29:28,865 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 22:29:30,937 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 22:29:31,434 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:29:31,435 - __main__ - INFO - ElevenLabs API key found
2025-02-22 22:29:31,459 - __main__ - INFO - OpenAI API key found
2025-02-22 22:29:31,476 - __main__ - INFO - Starting Quart application
2025-02-22 22:29:31,476 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 22:29:31,476 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:29:31,476 - __main__ - INFO - OpenAI API key present: True
2025-02-22 22:29:31,476 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 22:29:31,476 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 22:29:31,494 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 22:29:31,494 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 22:29:45,675 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 22:29:46,251 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:29:46,252 - __main__ - INFO - ElevenLabs API key found
2025-02-22 22:29:46,278 - __main__ - INFO - OpenAI API key found
2025-02-22 22:29:46,296 - __main__ - INFO - Starting Quart application
2025-02-22 22:29:46,296 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 22:29:46,296 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:29:46,296 - __main__ - INFO - OpenAI API key present: True
2025-02-22 22:29:46,296 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 22:29:46,297 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 22:29:46,325 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 22:29:46,325 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 22:29:47,328 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 22:29:47,845 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:29:47,846 - __main__ - INFO - ElevenLabs API key found
2025-02-22 22:29:47,871 - __main__ - INFO - OpenAI API key found
2025-02-22 22:29:47,887 - __main__ - INFO - Starting Quart application
2025-02-22 22:29:47,887 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 22:29:47,887 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:29:47,887 - __main__ - INFO - OpenAI API key present: True
2025-02-22 22:29:47,888 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 22:29:47,888 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 22:29:47,906 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 22:29:47,906 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 22:30:01,050 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49586): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49586)>
2025-02-22 22:30:01,052 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49587): <socket.socket fd=9, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49587)>
2025-02-22 22:30:01,060 - __main__ - INFO - Serving index page
2025-02-22 22:30:37,906 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49589): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49589)>
2025-02-22 22:30:37,913 - __main__ - INFO - Received script generation request
2025-02-22 22:30:37,914 - __main__ - DEBUG - Request data: {'prompt': 'Beautiful kitchen renovation with dark green features and white countertops with a gold accent.', 'duration': '30'}
2025-02-22 22:30:37,914 - __main__ - INFO - Generating scripts for duration: 30s
2025-02-22 22:30:37,914 - __main__ - INFO - Generating scripts for prompt: Beautiful kitchen renovation with dark green features and white countertops with a gold accent.... (duration: 30s)
2025-02-22 22:30:37,919 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a professional script writer specializing in voiceovers and commercials. \n                Create engaging, natural-sounding scripts that match the timing constraints perfectly. \n                Each script should be carefully timed where speaking at a natural pace would match the specified duration.'}, {'role': 'user', 'content': "Write 3 different 30-second script variations based on this prompt: Beautiful kitchen renovation with dark green features and white countertops with a gold accent.\n\n                Requirements:\n                1. Each script must be timed to be spoken in exactly 30 seconds at a natural pace\n                2. Use natural, conversational language\n                3. Make each variation distinct but equally engaging\n                4. Focus on clarity and impact\n                5. Avoid any audio/visual directions - just the spoken words\n                6. Keep the length to no more than 3 sentences.\n                7. Keep sentences short.\n                8. The last sentence should be a call-to-action like 'get your estimate' or 'learn more'.\n\n                Return ONLY the three script variations, separated by ||| (three pipes)."}], 'model': 'gpt-4'}}
2025-02-22 22:30:37,942 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-22 22:30:37,943 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-22 22:30:37,963 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10c46b590>
2025-02-22 22:30:37,963 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10c0d24d0> server_hostname='api.openai.com' timeout=5.0
2025-02-22 22:30:37,974 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10c46b470>
2025-02-22 22:30:37,974 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-22 22:30:37,975 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-22 22:30:37,975 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-22 22:30:37,975 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-22 22:30:37,975 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-22 22:30:45,099 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 22 Feb 2025 22:30:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-u65kabkbadcebd8ytdwynb4q'), (b'openai-processing-ms', b'6838'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'39694'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'459ms'), (b'x-request-id', b'req_c5b46dc15f18c6ca1f5c8a8234d306cd'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=8aEgjb53uIbd_NHqFMK__MjHiFM3pPRAF_5TzcVG1hE-1740263445-1.0.1.1-aPqf3gPM62slMo9U5JaWLVXneAXeXz20U9H4LrGJFQk3Ofag92E6J1Go5QSdDGZb68dOrl5Ag2YbvW72ap5g8A; path=/; expires=Sat, 22-Feb-25 23:00:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=G9yJAMVTb3GI3toNH0fW.h7_LUzKxZHOsx1EBhDJteg-1740263445151-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91626bf7bb60652a-LHR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-22 22:30:45,102 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-22 22:30:45,103 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-22 22:30:45,104 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-22 22:30:45,104 - httpcore.http11 - DEBUG - response_closed.started
2025-02-22 22:30:45,104 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-22 22:30:45,104 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sat, 22 Feb 2025 22:30:45 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-u65kabkbadcebd8ytdwynb4q'), ('openai-processing-ms', '6838'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '40000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '39694'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '459ms'), ('x-request-id', 'req_c5b46dc15f18c6ca1f5c8a8234d306cd'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=8aEgjb53uIbd_NHqFMK__MjHiFM3pPRAF_5TzcVG1hE-1740263445-1.0.1.1-aPqf3gPM62slMo9U5JaWLVXneAXeXz20U9H4LrGJFQk3Ofag92E6J1Go5QSdDGZb68dOrl5Ag2YbvW72ap5g8A; path=/; expires=Sat, 22-Feb-25 23:00:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=G9yJAMVTb3GI3toNH0fW.h7_LUzKxZHOsx1EBhDJteg-1740263445151-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '91626bf7bb60652a-LHR'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-02-22 22:30:45,104 - openai._base_client - DEBUG - request_id: req_c5b46dc15f18c6ca1f5c8a8234d306cd
2025-02-22 22:30:45,114 - __main__ - DEBUG - GPT-4 response: "Ever dreamt of an enchanting kitchen makeover? Step into luxury with our dark green and white renovation sensation. Elegant, bold, and utterly stylish. With its dramatic green hues and terrific white countertops, and just a hint of gold for that grand touch. Make your kitchen your favorite place to be. Get your free estimate today!" |||

"Be the trendsetter with a unique, luxurious kitchen design. We’re talking dark green features, pristine white countertops all complemented by subtle gold accents. It's not just a renovation, it's transforming your kitchen into an artist's canvas. Press pause on the mediocre and hit play on extraordinary. Learn more about our offbeat designs now!" |||

"What if your kitchen was more than just a kitchen? Imagine chic dark green design elements paired with stark white countertops, finished with a dash of gold. This isn't just a renovation, it's an aesthetic revolution right in the heart of your home. Ready for an avant-garde change? Get in touch for your very own kitchen transformation!"
2025-02-22 22:30:45,114 - __main__ - INFO - Generated 3 script variations
2025-02-22 22:30:45,114 - __main__ - INFO - Scripts generated successfully
2025-02-22 22:30:51,428 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49595): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49595)>
2025-02-22 22:30:51,433 - __main__ - INFO - Received script generation request
2025-02-22 22:30:51,433 - __main__ - DEBUG - Request data: {'prompt': 'Beautiful kitchen renovation with dark green features and white countertops with a gold accent.', 'duration': '10'}
2025-02-22 22:30:51,434 - __main__ - INFO - Generating scripts for duration: 10s
2025-02-22 22:30:51,434 - __main__ - INFO - Generating scripts for prompt: Beautiful kitchen renovation with dark green features and white countertops with a gold accent.... (duration: 10s)
2025-02-22 22:30:51,439 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a professional script writer specializing in voiceovers and commercials. \n                Create engaging, natural-sounding scripts that match the timing constraints perfectly. \n                Each script should be carefully timed where speaking at a natural pace would match the specified duration.'}, {'role': 'user', 'content': "Write 3 different 10-second script variations based on this prompt: Beautiful kitchen renovation with dark green features and white countertops with a gold accent.\n\n                Requirements:\n                1. Each script must be timed to be spoken in exactly 10 seconds at a natural pace\n                2. Use natural, conversational language\n                3. Make each variation distinct but equally engaging\n                4. Focus on clarity and impact\n                5. Avoid any audio/visual directions - just the spoken words\n                6. Keep the length to no more than 3 sentences.\n                7. Keep sentences short.\n                8. The last sentence should be a call-to-action like 'get your estimate' or 'learn more'.\n\n                Return ONLY the three script variations, separated by ||| (three pipes)."}], 'model': 'gpt-4'}}
2025-02-22 22:30:51,440 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-02-22 22:30:51,440 - httpcore.connection - DEBUG - close.started
2025-02-22 22:30:51,441 - httpcore.connection - DEBUG - close.complete
2025-02-22 22:30:51,441 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-02-22 22:30:51,448 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10c486240>
2025-02-22 22:30:51,448 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10c0d24d0> server_hostname='api.openai.com' timeout=5.0
2025-02-22 22:30:51,457 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10c485d00>
2025-02-22 22:30:51,457 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-22 22:30:51,458 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-22 22:30:51,458 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-22 22:30:51,458 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-22 22:30:51,458 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-22 22:30:54,877 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 22 Feb 2025 22:30:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-u65kabkbadcebd8ytdwynb4q'), (b'openai-processing-ms', b'3220'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'39694'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'459ms'), (b'x-request-id', b'req_a88a9ec1a45288e3b7f6974bace66d8c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'91626c4bfc7e652a-LHR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-02-22 22:30:54,879 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-02-22 22:30:54,879 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-22 22:30:54,880 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-22 22:30:54,880 - httpcore.http11 - DEBUG - response_closed.started
2025-02-22 22:30:54,880 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-22 22:30:54,880 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sat, 22 Feb 2025 22:30:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-u65kabkbadcebd8ytdwynb4q', 'openai-processing-ms': '3220', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '40000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '39694', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '459ms', 'x-request-id': 'req_a88a9ec1a45288e3b7f6974bace66d8c', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '91626c4bfc7e652a-LHR', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-02-22 22:30:54,881 - openai._base_client - DEBUG - request_id: req_a88a9ec1a45288e3b7f6974bace66d8c
2025-02-22 22:30:54,882 - __main__ - DEBUG - GPT-4 response: "Picture a stunning kitchen renovation! Dark green hues meet pristine white countertops accented with gold. Intrigued? Get your estimate today!" ||| "Discover your dream kitchen! Bold, rich green features expertly matched with white and gold detail. Now's the time – learn more!" ||| "Step into luxury with a revitalized kitchen, think deep green tones, white countertops and gold accents. Ready for this change? Request your quote now!"

2025-02-22 22:30:54,882 - __main__ - INFO - Generated 3 script variations
2025-02-22 22:30:54,882 - __main__ - INFO - Scripts generated successfully
2025-02-22 22:31:44,618 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49598): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49598)>
2025-02-22 22:31:44,623 - __main__ - INFO - Received voiceover generation request
2025-02-22 22:31:44,623 - __main__ - DEBUG - Request data: {'text': 'Create your dream kitchen with ElevenLabs Renovation. Get your free estimate today.', 'voice': 'wJqPPQ618aTW29mptyoc'}
2025-02-22 22:31:44,623 - __main__ - INFO - Generating voiceover for text: Create your dream kitchen with ElevenLabs Renovation. Get your free estimate today....
2025-02-22 22:31:44,623 - __main__ - INFO - Using voice ID: wJqPPQ618aTW29mptyoc
2025-02-22 22:31:44,623 - __main__ - DEBUG - Calling ElevenLabs API
2025-02-22 22:31:44,623 - __main__ - DEBUG - Converting audio generator to bytes
2025-02-22 22:31:44,625 - httpcore.connection - DEBUG - connect_tcp.started host='api.elevenlabs.io' port=443 local_address=None timeout=60 socket_options=None
2025-02-22 22:31:44,633 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10c487530>
2025-02-22 22:31:44,633 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10c0d2250> server_hostname='api.elevenlabs.io' timeout=60
2025-02-22 22:31:44,645 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10c487170>
2025-02-22 22:31:44,646 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-22 22:31:44,646 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-22 22:31:44,646 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-22 22:31:44,646 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-22 22:31:44,646 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-22 22:31:46,295 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Sat, 22 Feb 2025 22:31:44 GMT'), (b'server', b'uvicorn'), (b'request-id', b'VHrv3oALwQzUequ0uLZo'), (b'access-control-expose-headers', b'request-id, history-item-id, character-cost, regeneration-count, generation-info, current-concurrent-requests, maximum-concurrent-requests'), (b'history-item-id', b'drlGxRWGr9hGTEaajIs0'), (b'current-concurrent-requests', b'1'), (b'maximum-concurrent-requests', b'5'), (b'character-cost', b'83'), (b'tts-latency-ms', b'1337'), (b'Content-Length', b'91115'), (b'content-type', b'audio/mpeg'), (b'access-control-allow-origin', b'*'), (b'access-control-allow-headers', b'*'), (b'access-control-allow-methods', b'POST, PATCH, OPTIONS, DELETE, GET, PUT'), (b'access-control-max-age', b'600'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), (b'x-trace-id', b'2a13d90f8c2c3fd10c2074d724aa1e80'), (b'Via', b'1.1 google'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000')])
2025-02-22 22:31:46,297 - httpx - INFO - HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/wJqPPQ618aTW29mptyoc?output_format=mp3_44100_128 "HTTP/1.1 200 OK"
2025-02-22 22:31:46,297 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-22 22:31:46,326 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-22 22:31:46,327 - httpcore.http11 - DEBUG - response_closed.started
2025-02-22 22:31:46,327 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-22 22:31:46,327 - __main__ - DEBUG - Generated 91115 bytes of audio data
2025-02-22 22:31:46,327 - __main__ - DEBUG - Saving audio to /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp/voiceover_5759298267226778461.mp3
2025-02-22 22:31:46,328 - __main__ - INFO - Voiceover generated successfully
2025-02-22 22:31:46,330 - asyncio - WARNING - Executing <Task finished name='Task-39' coro=<ASGIHTTPConnection.handle_request() done, defined at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/asgi.py:106> result=None created at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 1.707 seconds
2025-02-22 22:31:46,338 - __main__ - INFO - Serving audio file: voiceover_5759298267226778461.mp3
2025-02-22 22:31:46,355 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49600): <socket.socket fd=18, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49600)>
2025-02-22 22:34:50,331 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 22:34:50,890 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:34:50,890 - __main__ - INFO - ElevenLabs API key found
2025-02-22 22:34:50,915 - __main__ - INFO - OpenAI API key found
2025-02-22 22:34:50,932 - __main__ - INFO - Starting Quart application
2025-02-22 22:34:50,932 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 22:34:50,932 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:34:50,932 - __main__ - INFO - OpenAI API key present: True
2025-02-22 22:34:50,932 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 22:34:50,932 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 22:34:50,950 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 22:34:50,950 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 22:34:52,970 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 22:34:53,477 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:34:53,478 - __main__ - INFO - ElevenLabs API key found
2025-02-22 22:34:53,503 - __main__ - INFO - OpenAI API key found
2025-02-22 22:34:53,519 - __main__ - INFO - Starting Quart application
2025-02-22 22:34:53,519 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 22:34:53,519 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:34:53,519 - __main__ - INFO - OpenAI API key present: True
2025-02-22 22:34:53,519 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 22:34:53,519 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 22:34:53,536 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 22:34:53,537 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 22:35:48,618 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49661): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49661)>
2025-02-22 22:35:48,620 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49662): <socket.socket fd=9, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49662)>
2025-02-22 22:35:48,633 - __main__ - INFO - Serving index page
2025-02-22 22:36:34,031 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49848): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49848)>
2025-02-22 22:36:34,036 - __main__ - INFO - Received voiceover generation request
2025-02-22 22:36:34,037 - __main__ - DEBUG - Request data: {'text': 'Create your dream kitchen with ElevenLabs renovation. Get your free estimate today.', 'voice': 'wJqPPQ618aTW29mptyoc'}
2025-02-22 22:36:34,037 - __main__ - INFO - Generating voiceover for text: Create your dream kitchen with ElevenLabs renovation. Get your free estimate today....
2025-02-22 22:36:34,037 - __main__ - INFO - Using voice ID: wJqPPQ618aTW29mptyoc
2025-02-22 22:36:34,037 - __main__ - DEBUG - Calling ElevenLabs API
2025-02-22 22:36:34,037 - __main__ - DEBUG - Converting audio generator to bytes
2025-02-22 22:36:34,040 - httpcore.connection - DEBUG - connect_tcp.started host='api.elevenlabs.io' port=443 local_address=None timeout=60 socket_options=None
2025-02-22 22:36:34,066 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106c36570>
2025-02-22 22:36:34,067 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1069d2350> server_hostname='api.elevenlabs.io' timeout=60
2025-02-22 22:36:34,079 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106c35ee0>
2025-02-22 22:36:34,080 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-22 22:36:34,080 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-22 22:36:34,080 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-22 22:36:34,080 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-22 22:36:34,080 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-22 22:36:35,642 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Sat, 22 Feb 2025 22:36:34 GMT'), (b'server', b'uvicorn'), (b'request-id', b'IWmR0bef8SWX46sYP4hK'), (b'access-control-expose-headers', b'request-id, history-item-id, character-cost, regeneration-count, generation-info, current-concurrent-requests, maximum-concurrent-requests'), (b'history-item-id', b'nzvPEypjV1NIeuc7UbzU'), (b'current-concurrent-requests', b'1'), (b'maximum-concurrent-requests', b'5'), (b'character-cost', b'83'), (b'tts-latency-ms', b'1317'), (b'Content-Length', b'91951'), (b'content-type', b'audio/mpeg'), (b'access-control-allow-origin', b'*'), (b'access-control-allow-headers', b'*'), (b'access-control-allow-methods', b'POST, PATCH, OPTIONS, DELETE, GET, PUT'), (b'access-control-max-age', b'600'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), (b'x-trace-id', b'8c44d675902afae6837954a1c158c929'), (b'Via', b'1.1 google'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000')])
2025-02-22 22:36:35,644 - httpx - INFO - HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/wJqPPQ618aTW29mptyoc?output_format=mp3_44100_128 "HTTP/1.1 200 OK"
2025-02-22 22:36:35,644 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-22 22:36:35,694 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-22 22:36:35,694 - httpcore.http11 - DEBUG - response_closed.started
2025-02-22 22:36:35,695 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-22 22:36:35,695 - __main__ - DEBUG - Generated 91951 bytes of audio data
2025-02-22 22:36:35,695 - __main__ - DEBUG - Saving audio to /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp/voiceover_7425155311266719616.mp3
2025-02-22 22:36:35,696 - __main__ - INFO - Voiceover generated successfully
2025-02-22 22:36:35,699 - asyncio - WARNING - Executing <Task finished name='Task-23' coro=<ASGIHTTPConnection.handle_request() done, defined at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/asgi.py:106> result=None created at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 1.663 seconds
2025-02-22 22:36:35,712 - __main__ - INFO - Serving audio file: voiceover_7425155311266719616.mp3
2025-02-22 22:36:35,731 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 49859): <socket.socket fd=17, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 49859)>
2025-02-22 22:38:04,521 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 22:38:05,201 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:38:05,202 - __main__ - INFO - ElevenLabs API key found
2025-02-22 22:38:05,230 - __main__ - INFO - OpenAI API key found
2025-02-22 22:38:05,247 - __main__ - INFO - Starting Quart application
2025-02-22 22:38:05,247 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 22:38:05,247 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:38:05,247 - __main__ - INFO - OpenAI API key present: True
2025-02-22 22:38:05,247 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 22:38:05,247 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 22:38:05,267 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 22:38:05,268 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 22:38:06,270 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 22:38:06,786 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:38:06,787 - __main__ - INFO - ElevenLabs API key found
2025-02-22 22:38:06,812 - __main__ - INFO - OpenAI API key found
2025-02-22 22:38:06,828 - __main__ - INFO - Starting Quart application
2025-02-22 22:38:06,828 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 22:38:06,828 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:38:06,828 - __main__ - INFO - OpenAI API key present: True
2025-02-22 22:38:06,828 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 22:38:06,828 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 22:38:06,846 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 22:38:06,846 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 22:39:07,283 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 50560): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 50560)>
2025-02-22 22:39:07,286 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 50561): <socket.socket fd=9, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 50561)>
2025-02-22 22:39:07,299 - __main__ - INFO - Serving index page
2025-02-22 22:39:17,816 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 50606): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 50606)>
2025-02-22 22:39:17,820 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:39:17,823 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:39:17,825 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:39:17,826 - __main__ - INFO - Received video upload request
2025-02-22 22:39:17,827 - __main__ - ERROR - Error processing video upload:
2025-02-22 22:39:17,829 - __main__ - ERROR - Traceback (most recent call last):
  File "/Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/voiceover_test.py", line 771, in upload_video
    if 'video' not in (await request.files):
                       ^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/wrappers/request.py", line 326, in files
    await self._load_form_data()
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/wrappers/request.py", line 342, in _load_form_data
    self._form, self._files = await asyncio.wait_for(
                              ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py", line 520, in wait_for
    return await fut
           ^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/formparser.py", line 80, in parse
    return await parse_func(self, body, mimetype, content_length, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/formparser.py", line 107, in _parse_multipart
    return await parser.parse(body, boundary, content_length)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/formparser.py", line 201, in parse
    async for data in body:
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/wrappers/request.py", line 74, in __anext__
    raise self._must_raise
werkzeug.exceptions.RequestEntityTooLarge: 413 Request Entity Too Large: The data value transmitted exceeds the capacity limit.

2025-02-22 22:39:52,049 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 22:39:52,811 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:39:52,812 - __main__ - INFO - ElevenLabs API key found
2025-02-22 22:39:52,842 - __main__ - INFO - OpenAI API key found
2025-02-22 22:39:52,858 - __main__ - INFO - Starting Quart application
2025-02-22 22:39:52,858 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 22:39:52,858 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:39:52,858 - __main__ - INFO - OpenAI API key present: True
2025-02-22 22:39:52,858 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 22:39:52,858 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 22:39:52,878 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 22:39:52,878 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 22:39:53,884 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 22:39:54,396 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:39:54,397 - __main__ - INFO - ElevenLabs API key found
2025-02-22 22:39:54,422 - __main__ - INFO - OpenAI API key found
2025-02-22 22:39:54,438 - __main__ - INFO - Starting Quart application
2025-02-22 22:39:54,438 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 22:39:54,438 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:39:54,438 - __main__ - INFO - OpenAI API key present: True
2025-02-22 22:39:54,438 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 22:39:54,438 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 22:39:54,456 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 22:39:54,456 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 22:40:11,068 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 50872): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 50872)>
2025-02-22 22:40:11,070 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 50873): <socket.socket fd=9, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 50873)>
2025-02-22 22:40:11,078 - __main__ - INFO - Serving index page
2025-02-22 22:40:16,092 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 50892): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 50892)>
2025-02-22 22:40:16,096 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,099 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,100 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,101 - __main__ - INFO - Received video upload request
2025-02-22 22:40:16,103 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,104 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,107 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,108 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,109 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,110 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,111 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,112 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,113 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,114 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,115 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,115 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,116 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,117 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,117 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,118 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,118 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,119 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,120 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,121 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,122 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,123 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,124 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,124 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,126 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,126 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,127 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,128 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,128 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,129 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,129 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,130 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,131 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,132 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,132 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,133 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,134 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,134 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,135 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,135 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,136 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,136 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,137 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,137 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,138 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,138 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,138 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,139 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,140 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,140 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,141 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,141 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,142 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,142 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,143 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,143 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,144 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,144 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,145 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,146 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,146 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,147 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,147 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,148 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,149 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,149 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,150 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,150 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,151 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,151 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,151 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,152 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,152 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,153 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,153 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,154 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,154 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,154 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,155 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,155 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,156 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,156 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,157 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,157 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,158 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,158 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,158 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,159 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,159 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,160 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,160 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,160 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,161 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,162 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,162 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,162 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,163 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,164 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,164 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,165 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,165 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,165 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,166 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,167 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,167 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,168 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,168 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,168 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,169 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,169 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,170 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,170 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,171 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,171 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,172 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,172 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,173 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,173 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,173 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,174 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,174 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,175 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,175 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,175 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,176 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,176 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,177 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,177 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,179 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,179 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,179 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,180 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,180 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,181 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,181 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,181 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,182 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,182 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,183 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,183 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,184 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,184 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,185 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,185 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,185 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,186 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,186 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,186 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,187 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,187 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,188 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,188 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,188 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,189 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,189 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,190 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,190 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,190 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,191 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,191 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,192 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,192 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,192 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,192 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,193 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,193 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,194 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,194 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,195 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,195 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,195 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,196 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=idle write=<idle, bufsize=0>> pauses reading
2025-02-22 22:40:16,196 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>> resumes reading
2025-02-22 22:40:16,416 - __main__ - INFO - Video saved to /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp/ai-video.mp4
2025-02-22 22:40:16,422 - __main__ - INFO - Serving video file: ai-video.mp4
2025-02-22 22:40:16,851 - asyncio - DEBUG - <asyncio.streams.StreamReaderProtocol object at 0x106333440> pauses writing
2025-02-22 22:40:30,483 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 50956): <socket.socket fd=14, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 50956)>
2025-02-22 22:40:30,488 - __main__ - INFO - Received voiceover generation request
2025-02-22 22:40:30,488 - __main__ - DEBUG - Request data: {'text': 'Create your dream kitchen with ElevenLabs renovation. Get your free estimate today.', 'voice': 'wJqPPQ618aTW29mptyoc'}
2025-02-22 22:40:30,488 - __main__ - INFO - Generating voiceover for text: Create your dream kitchen with ElevenLabs renovation. Get your free estimate today....
2025-02-22 22:40:30,488 - __main__ - INFO - Using voice ID: wJqPPQ618aTW29mptyoc
2025-02-22 22:40:30,488 - __main__ - DEBUG - Calling ElevenLabs API
2025-02-22 22:40:30,488 - __main__ - DEBUG - Converting audio generator to bytes
2025-02-22 22:40:30,490 - httpcore.connection - DEBUG - connect_tcp.started host='api.elevenlabs.io' port=443 local_address=None timeout=60 socket_options=None
2025-02-22 22:40:30,498 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107198680>
2025-02-22 22:40:30,498 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1064c6350> server_hostname='api.elevenlabs.io' timeout=60
2025-02-22 22:40:30,512 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10636c7a0>
2025-02-22 22:40:30,512 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-02-22 22:40:30,512 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-02-22 22:40:30,512 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-02-22 22:40:30,512 - httpcore.http11 - DEBUG - send_request_body.complete
2025-02-22 22:40:30,512 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-02-22 22:40:32,092 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Sat, 22 Feb 2025 22:40:29 GMT'), (b'server', b'uvicorn'), (b'request-id', b'2B3zYDIsbNRC2SFB9XFu'), (b'access-control-expose-headers', b'request-id, history-item-id, character-cost, regeneration-count, generation-info, current-concurrent-requests, maximum-concurrent-requests'), (b'history-item-id', b'H4SCO8gntbM2jqADNUVi'), (b'current-concurrent-requests', b'1'), (b'maximum-concurrent-requests', b'5'), (b'character-cost', b'83'), (b'tts-latency-ms', b'1342'), (b'Content-Length', b'91951'), (b'content-type', b'audio/mpeg'), (b'access-control-allow-origin', b'*'), (b'access-control-allow-headers', b'*'), (b'access-control-allow-methods', b'POST, PATCH, OPTIONS, DELETE, GET, PUT'), (b'access-control-max-age', b'600'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains'), (b'x-trace-id', b'be26a8742580150646bd133bf81c4aed'), (b'Via', b'1.1 google'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000')])
2025-02-22 22:40:32,094 - httpx - INFO - HTTP Request: POST https://api.elevenlabs.io/v1/text-to-speech/wJqPPQ618aTW29mptyoc?output_format=mp3_44100_128 "HTTP/1.1 200 OK"
2025-02-22 22:40:32,094 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-02-22 22:40:32,125 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-02-22 22:40:32,125 - httpcore.http11 - DEBUG - response_closed.started
2025-02-22 22:40:32,125 - httpcore.http11 - DEBUG - response_closed.complete
2025-02-22 22:40:32,126 - __main__ - DEBUG - Generated 91951 bytes of audio data
2025-02-22 22:40:32,126 - __main__ - DEBUG - Saving audio to /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp/voiceover_5689863120399306359.mp3
2025-02-22 22:40:32,126 - __main__ - INFO - Voiceover generated successfully
2025-02-22 22:40:32,129 - asyncio - WARNING - Executing <Task finished name='Task-33' coro=<ASGIHTTPConnection.handle_request() done, defined at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/quart/asgi.py:106> result=None created at /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:695> took 1.641 seconds
2025-02-22 22:40:32,137 - __main__ - INFO - Serving audio file: voiceover_5689863120399306359.mp3
2025-02-22 22:40:32,140 - asyncio - DEBUG - <_SelectorSocketTransport fd=8 read=polling write=<idle, bufsize=0>>: Fatal write error on socket transport
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/selector_events.py", line 1102, in _write_sendmsg
    nbytes = self._sock.sendmsg(self._get_sendmsg_buffer())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe
2025-02-22 22:40:32,159 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 50962): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 50962)>
2025-02-22 22:40:38,286 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 50992): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 50992)>
2025-02-22 22:40:38,292 - __main__ - INFO - Received video combination request
2025-02-22 22:40:38,293 - __main__ - DEBUG - Request data: {'video_path': '/Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp/ai-video.mp4', 'audio_url': '/api/audio/voiceover_5689863120399306359.mp3', 'text': 'Create your dream kitchen with ElevenLabs renovation. Get your free estimate today.', 'duration': 30}
2025-02-22 22:40:38,293 - __main__ - INFO - Generating subtitles...
2025-02-22 22:40:38,293 - __main__ - INFO - Generating SRT subtitles for text: Create your dream kitchen with ElevenLabs renovation. Get your free estimate today....
2025-02-22 22:40:38,293 - __main__ - DEBUG - Saving subtitles to /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp/subtitles_3210071512350137050.srt
2025-02-22 22:40:38,294 - __main__ - INFO - Subtitles generated successfully
2025-02-22 22:40:38,294 - __main__ - INFO - Combining video, audio and subtitles...
2025-02-22 22:40:38,294 - __main__ - INFO - Combining video, audio and subtitles...
2025-02-22 22:40:38,295 - asyncio - DEBUG - execute program 'ffmpeg' stdout=<pipe> stderr=<pipe>
2025-02-22 22:40:38,306 - asyncio - DEBUG - process 'ffmpeg' created: pid 89019
2025-02-22 22:40:38,309 - asyncio - DEBUG - Read pipe 9 connected: (<_UnixReadPipeTransport fd=9 polling>, <ReadSubprocessPipeProto fd=1 pipe=<_UnixReadPipeTransport fd=9 polling>>)
2025-02-22 22:40:38,310 - asyncio - DEBUG - Read pipe 18 connected: (<_UnixReadPipeTransport fd=18 polling>, <ReadSubprocessPipeProto fd=2 pipe=<_UnixReadPipeTransport fd=18 polling>>)
2025-02-22 22:40:38,311 - asyncio - INFO - execute program 'ffmpeg': <_UnixSubprocessTransport pid=89019 running stdout=<_UnixReadPipeTransport fd=9 polling> stderr=<_UnixReadPipeTransport fd=18 polling>>
2025-02-22 22:40:38,311 - asyncio - DEBUG - <Process 89019> communicate: read stdout
2025-02-22 22:40:38,312 - asyncio - DEBUG - <Process 89019> communicate: read stderr
2025-02-22 22:40:40,491 - asyncio - INFO - <_UnixReadPipeTransport fd=18 polling> was closed by peer
2025-02-22 22:40:40,491 - asyncio - DEBUG - process 89019 exited with returncode 0
2025-02-22 22:40:40,492 - asyncio - INFO - <_UnixReadPipeTransport fd=9 polling> was closed by peer
2025-02-22 22:40:40,492 - asyncio - INFO - <_UnixSubprocessTransport pid=89019 running stdout=<_UnixReadPipeTransport closed fd=9 closed> stderr=<_UnixReadPipeTransport closed fd=18 closed>> exited with return code 0
2025-02-22 22:40:40,492 - asyncio - DEBUG - <Process 89019> communicate: close stderr
2025-02-22 22:40:40,492 - asyncio - DEBUG - <Process 89019> communicate: close stdout
2025-02-22 22:40:40,492 - __main__ - INFO - Successfully combined video, audio and subtitles to: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp/final_ai-video.mp4
2025-02-22 22:40:40,493 - __main__ - INFO - Process completed successfully
2025-02-22 22:40:40,497 - __main__ - INFO - Serving video file: final_ai-video.mp4
2025-02-22 22:40:47,173 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 51017): <socket.socket fd=8, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 51017)>
2025-02-22 22:40:47,174 - asyncio - DEBUG - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> got a new connection from ('127.0.0.1', 51018): <socket.socket fd=9, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001), raddr=('127.0.0.1', 51018)>
2025-02-22 22:40:58,800 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
2025-02-22 22:40:59,313 - __main__ - INFO - Looking for .env file at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:40:59,314 - __main__ - INFO - ElevenLabs API key found
2025-02-22 22:40:59,338 - __main__ - INFO - OpenAI API key found
2025-02-22 22:40:59,354 - __main__ - INFO - Starting Quart application
2025-02-22 22:40:59,355 - __main__ - INFO - Temporary directory created at: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/tools/test_pages/temp
2025-02-22 22:40:59,355 - __main__ - INFO - Environment variables loaded from: /Users/chris/repos/projects/elevenlabs-hackathon/ai_cmo/.env
2025-02-22 22:40:59,355 - __main__ - INFO - OpenAI API key present: True
2025-02-22 22:40:59,355 - __main__ - INFO - ElevenLabs API key present: True
2025-02-22 22:40:59,355 - asyncio - DEBUG - Using selector: KqueueSelector
2025-02-22 22:40:59,373 - asyncio - INFO - <Server sockets=(<asyncio.TransportSocket fd=7, family=2, type=1, proto=0, laddr=('127.0.0.1', 5001)>,)> is serving
2025-02-22 22:40:59,373 - hypercorn.error - INFO - Running on http://127.0.0.1:5001 (CTRL + C to quit)
2025-02-22 22:41:06,506 - asyncio - DEBUG - Close <_UnixSelectorEventLoop running=False closed=False debug=True>
